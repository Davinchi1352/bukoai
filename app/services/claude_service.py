"""
Claude AI Service for Book Generation
====================================
Handles all interactions with Claude API for generating book content.
Supports streaming, retry logic, and error handling.
"""

import json
import logging
import asyncio
from typing import Dict, Any, AsyncIterator, Optional, List
from datetime import datetime, timezone
import anthropic
from anthropic import AsyncAnthropic, APIError, APIConnectionError, RateLimitError
import structlog
from flask import current_app
from app.utils.retry import exponential_backoff_retry
from app.services.claude_service_coherence import BookCoherenceManager
from app.utils.structured_logging import track_book_generation_start, track_claude_api_call, track_generation_complete
import httpx
import time

logger = structlog.get_logger()


class ClaudeService:
    """
    Servicio optimizado para generaci√≥n completa de libros con Claude AI.
    
    Este servicio est√° dise√±ado espec√≠ficamente para generar libros completos
    en una sola operaci√≥n, utilizando streaming SSE para feedback en tiempo real
    y el modelo m√°s avanzado de Claude (claude-sonnet-4-20250514) con capacidades
    de thinking extendido.
    
    Caracter√≠sticas principales:
    - Generaci√≥n completa de libros (no por cap√≠tulos)
    - Streaming en tiempo real con WebSocket
    - Thinking transparente para mostrar el proceso de an√°lisis
    - M√©tricas detalladas de generaci√≥n
    - Manejo robusto de errores
    """
    
    def __init__(self):
        """Initialize Claude service with API client."""
        self.api_key = current_app.config.get('ANTHROPIC_API_KEY')
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not configured")
        
        # Configurar timeouts generosos pero efectivos para libros de calidad
        http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(
                connect=30.0,      # 30 segundos para conectar
                read=1800.0,       # 30 minutos para leer (libros extensos)
                write=60.0,        # 1 minuto para escribir
                pool=300.0         # 5 minutos para pool
            ),
            limits=httpx.Limits(
                max_keepalive_connections=5,
                max_connections=10,
                keepalive_expiry=300
            )
        )
        
        self.client = AsyncAnthropic(
            api_key=self.api_key,
            http_client=http_client
        )
        
        self.model = current_app.config.get('CLAUDE_MODEL', 'claude-sonnet-4-20250514')
        # üöÄ MAX_TOKENS OPTIMIZADOS: Eficiencia m√°xima SIN comprometer p√°ginas
        self.max_tokens_config = {
            'architecture': 12000,      # üöÄ Reducido de 16K‚Üí12K - Arquitectura eficiente
            'chunk_main': 32000,        # üöÄ Aumentado de 28K‚Üí32K - Chunks M√ÅS GRANDES = menos llamadas
            'introduction': 6000,       # üöÄ Reducido de 8K‚Üí6K - Introducciones eficientes
            'conclusion': 6000,         # üöÄ Reducido de 8K‚Üí6K - Conclusiones eficientes  
            'continuation': 20000,      # üöÄ Aumentado de 16K‚Üí20K - Continuaciones m√°s sustanciales
            'expansion': 10000          # üöÄ Reducido de 12K‚Üí10K - Expansiones precisas
        }
        self.max_tokens = current_app.config.get('CLAUDE_MAX_TOKENS', 28000)  # Default optimizado
        self.temperature = current_app.config.get('CLAUDE_TEMPERATURE', 1.0)
        self.thinking_budget = current_app.config.get('CLAUDE_THINKING_BUDGET', 35000)  # üöÄ AMPLIADO: Aumentado para pensamiento extendido de alta calidad
        
        # Multi-chunk configuration OPTIMIZADO para VELOCIDAD + CALIDAD
        self.chunk_overlap = 500  # Tokens de overlap entre chunks para continuidad
        self.max_chunks = 3       # üöÄ OPTIMIZADO: Reducido de 5‚Üí3 para VELOCIDAD m√°xima
        
        # Timeouts generosos para contenidos extensos de alta calidad
        self.architecture_timeout = 2400  # 40 minutos para arquitectura (contenidos extensos)
        self.chunk_timeout = 3600         # 60 minutos por chunk (sin cortes prematuros)
        self.thinking_timeout = 1200      # 20 minutos adicionales para thinking complejo
        
        # Circuit breaker para 10K usuarios - balance entre estabilidad y disponibilidad
        self.error_count = 0
        self.max_errors = 5               # M√°s tolerancia con alta carga
        self.circuit_open_time = None
        self.circuit_timeout = 300        # 5 minutos de espera (recuperaci√≥n r√°pida)
        
        # Monitoreo de progreso optimizado para alta concurrencia
        self.last_progress_time = None
        self.progress_timeout = 1200      # 20 minutos sin progreso = posible cuelgue
        self.progress_check_interval = 50 # Verificar progreso cada 50 chunks (menos overhead)
        
        # Default coherence manager (se reconfigura por libro)
        self.coherence_manager = BookCoherenceManager()
        
        # Retry configuration
        self.max_retries = current_app.config.get('CLAUDE_MAX_RETRIES', 3)
        self.retry_delay = current_app.config.get('CLAUDE_RETRY_DELAY', 1.0)
    
    def _get_coherence_manager_for_book(self, book_params: Dict[str, Any]) -> BookCoherenceManager:
        """Crea un coherence manager configurado espec√≠ficamente para el formato del libro"""
        page_size = book_params.get('page_size', 'pocket')
        line_spacing = book_params.get('line_spacing', 'medium')
        
        logger.info("creating_book_specific_coherence_manager", 
                   page_size=page_size, 
                   line_spacing=line_spacing)
        
        return BookCoherenceManager(page_size=page_size, line_spacing=line_spacing)
    
    def _get_optimized_tokens(self, content_type: str) -> int:
        """üöÄ Obtiene tokens optimizados seg√∫n tipo de contenido"""
        return self.max_tokens_config.get(content_type, self.max_tokens)
    
    def _get_optimized_thinking_budget(self, content_type: str) -> int:
        """üöÄ Obtiene thinking budget optimizado seg√∫n tipo de contenido"""
        max_tokens = self._get_optimized_tokens(content_type)
        # üß† PENSAMIENTO EXTENDIDO: Usar todo el budget disponible para m√°xima calidad
        return min(max_tokens - 500, self.thinking_budget)  # Reducido margen de 1000‚Üí500 para m√°s thinking
    
    # =====================================
    # CIRCUIT BREAKER Y MONITOREO
    # =====================================
    
    def _check_circuit_breaker(self):
        """Verifica si el circuit breaker est√° abierto"""
        if self.circuit_open_time:
            if datetime.now(timezone.utc).timestamp() - self.circuit_open_time < self.circuit_timeout:
                raise Exception(f"Circuit breaker abierto. Esperando {self.circuit_timeout}s")
            else:
                # Reset circuit breaker
                self.circuit_open_time = None
                self.error_count = 0
                logger.info("circuit_breaker_reset", 
                           after_timeout=self.circuit_timeout)
    
    def _handle_api_error(self, error: Exception):
        """Maneja errores de API y actualiza circuit breaker"""
        self.error_count += 1
        logger.error("claude_api_error", 
                    error=str(error),
                    error_count=self.error_count,
                    max_errors=self.max_errors)
        
        if self.error_count >= self.max_errors:
            self.circuit_open_time = datetime.now(timezone.utc).timestamp()
            logger.error("circuit_breaker_opened", 
                        error_count=self.error_count,
                        timeout=self.circuit_timeout)
    
    def _handle_api_success(self):
        """Maneja √©xito de API y resetea contadores"""
        if self.error_count > 0:
            logger.info("claude_api_recovered", 
                       previous_errors=self.error_count)
            self.error_count = 0
    
    def _update_progress(self, book_id: int, operation: str, details: str = None):
        """Actualiza el timestamp de progreso para monitoreo inteligente"""
        self.last_progress_time = datetime.now(timezone.utc).timestamp()
        logger.info("claude_progress_update",
                   book_id=book_id,
                   operation=operation,
                   details=details,
                   timestamp=self.last_progress_time)
    
    def _check_progress_timeout(self, book_id: int, operation: str) -> bool:
        """Verifica si ha pasado demasiado tiempo sin progreso (posible cuelgue)"""
        if not self.last_progress_time:
            return False
            
        time_since_progress = datetime.now(timezone.utc).timestamp() - self.last_progress_time
        
        if time_since_progress > self.progress_timeout:
            logger.warning("possible_hang_detected",
                          book_id=book_id,
                          operation=operation,
                          time_since_progress=time_since_progress,
                          progress_timeout=self.progress_timeout)
            return True
            
        return False
    
    # =====================================
    # M√âTODOS PRINCIPALES DE GENERACI√ìN
    # =====================================
    
    async def generate_book_architecture(self, book_id: int, book_params: Dict[str, Any]) -> Dict[str, Any]:
        """
        Genera √∫nicamente la arquitectura del libro (estructura, cap√≠tulos, personajes, etc.)
        para que el usuario pueda revisar y aprobar antes de la generaci√≥n completa.
        
        Args:
            book_id: ID del libro
            book_params: Par√°metros del libro
            
        Returns:
            Resultado con la arquitectura generada
        """
        try:
            # Verificar circuit breaker
            self._check_circuit_breaker()
            
            # Iniciar tracking de generaci√≥n
            track_book_generation_start(book_id, book_params.get('user_id', 0), 
                                       'architecture', book_params)
            
            # Preparar el prompt espec√≠fico para arquitectura
            messages = self._build_architecture_messages(book_params)
            
            # Track inicio de llamada a Claude API
            api_start_time = time.time()
            
            # Variables para acumular respuesta
            full_content = []
            thinking_content = []
            chunk_count = 0
            
            # Emisi√≥n de evento de inicio
            from app.routes.websocket import emit_book_progress_update, emit_generation_log
            
            emit_book_progress_update(book_id, {
                'current': 5,
                'total': 100,
                'status': 'connecting',
                'status_message': 'Conectando con Claude AI para generar arquitectura...',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            
            # üöÄ OPTIMIZACI√ìN: Tokens espec√≠ficos optimizados para arquitectura
            arch_max_tokens = self._get_optimized_tokens('architecture')  # 16000 optimizado
            arch_budget_tokens = self._get_optimized_thinking_budget('architecture')  # Optimizado
            
            logger.info("starting_architecture_stream",
                       book_id=book_id,
                       max_tokens=arch_max_tokens,
                       thinking_budget=arch_budget_tokens,
                       timeout=self.architecture_timeout)
            
            # Usar timeout generoso pero efectivo para arquitectura de calidad
            async with asyncio.timeout(self.architecture_timeout):
                async with self.client.messages.stream(
                    model=self.model,
                    max_tokens=arch_max_tokens,
                    temperature=self.temperature,
                    messages=messages,
                    thinking={
                        "type": "enabled",
                        "budget_tokens": arch_budget_tokens
                    },
                ) as stream:
                    
                    emit_book_progress_update(book_id, {
                        'current': 15,
                        'total': 100,
                        'status': 'thinking',
                        'status_message': 'Claude est√° dise√±ando la arquitectura de tu libro...',
                        'timestamp': datetime.now(timezone.utc).isoformat()
                    })
                    
                    current_block_index = None
                    
                    async for event in stream:
                        chunk_count += 1
                        
                        # Debug: Log todos los tipos de eventos para investigar thinking_delta
                        if hasattr(event, 'type'):
                            if 'thinking' in str(event.type).lower() or chunk_count <= 5:  # Log thinking events + primeros 5
                                logger.info("stream_event_debug", 
                                           book_id=book_id,
                                           event_type=event.type,
                                           chunk_count=chunk_count,
                                           has_delta=hasattr(event, 'delta'),
                                           event_attributes=list(vars(event).keys()) if hasattr(event, '__dict__') else [])
                        
                        # Actualizar progreso optimizado para 10K usuarios (menos overhead)
                        if chunk_count % self.progress_check_interval == 0:
                            self._update_progress(book_id, "architecture_generation", 
                                                f"Procesando chunk {chunk_count}")
                        
                        # Thinking blocks
                        if event.type == "content_block_start" and hasattr(event, 'content_block') and event.content_block.type == "thinking":
                            current_block_index = event.index
                            self._update_progress(book_id, "architecture_thinking", "Iniciando an√°lisis")
                            emit_generation_log(book_id, 'thinking', 'Analizando requerimientos y dise√±ando estructura...')
                            
                        elif event.type == "content_block_delta" and hasattr(event, 'delta'):
                            # NUEVO: Thinking content via thinking_delta (seg√∫n documentaci√≥n Anthropic)
                            if hasattr(event.delta, 'type') and event.delta.type == "thinking_delta":
                                if hasattr(event.delta, 'thinking'):
                                    thinking_content.append(event.delta.thinking)
                                    if chunk_count % (self.progress_check_interval * 3) == 0:
                                        emit_book_progress_update(book_id, {
                                            'current': 25,
                                            'total': 100,
                                            'status': 'thinking',
                                            'status_message': f'Claude pensando profundamente... ({len("".join(thinking_content))} chars)',
                                            'timestamp': datetime.now(timezone.utc).isoformat()
                                        })
                            # Texto normal via text_delta
                            elif hasattr(event.delta, 'text'):
                                text_chunk = event.delta.text
                                
                                # Si es contenido normal (no thinking)
                                if current_block_index is None or event.index != current_block_index:
                                    full_content.append(text_chunk)
                                    
                                    if chunk_count % (self.progress_check_interval * 2) == 0:  # Menos updates de UI
                                        emit_book_progress_update(book_id, {
                                            'current': 25,
                                            'total': 100,
                                            'status': 'thinking',
                                            'status_message': f'Estructurando cap√≠tulos... ({chunk_count} chunks)',
                                            'timestamp': datetime.now(timezone.utc).isoformat()
                                        })
                                
                                # Content principal
                                else:
                                    full_content.append(text_chunk)
                                    
                                    if chunk_count % self.progress_check_interval == 0:
                                        progress_pct = min(85, 50 + (chunk_count // 20))  # M√°s granular
                                        emit_book_progress_update(book_id, {
                                            'current': progress_pct,
                                            'total': 100,
                                            'status': 'writing',
                                            'status_message': f'Generando arquitectura... ({chunk_count} chunks procesados)',
                                            'timestamp': datetime.now(timezone.utc).isoformat()
                                        })
                        
                        elif event.type == "content_block_stop":
                            if current_block_index == event.index:
                                emit_generation_log(book_id, 'thinking', 'An√°lisis completado')
                                current_block_index = None
                            else:
                                emit_book_progress_update(book_id, {
                                    'current': 90,
                                    'total': 100,
                                    'status': 'finalizing',
                                    'status_message': 'Finalizando arquitectura del libro...',
                                    'timestamp': datetime.now(timezone.utc).isoformat()
                                })
                
                    # Obtener mensaje final
                    final_message = await stream.get_final_message()
                    
                    # Track finalizaci√≥n de Claude API call
                    api_duration = time.time() - api_start_time
                    total_tokens = (final_message.usage.input_tokens + 
                                  final_message.usage.output_tokens + 
                                  getattr(final_message.usage, 'thinking_tokens', 0))
                    
                    track_claude_api_call(book_id, 'architecture_generation', api_duration,
                                        total_tokens, 'success', self.model)
                    
                    # Marcar √©xito en circuit breaker
                    self._handle_api_success()
                    
                    # Parsear la arquitectura generada
                    complete_content = ''.join(full_content)
                    complete_thinking = ''.join(thinking_content)
                    
                    # Intentar parsear como JSON con parser robusto
                    import json
                    import re
                    
                    def extract_json_from_response(content: str) -> dict:
                        """
                        Extrae JSON de respuesta de Claude de manera robusta
                        """
                        # 1. Intentar parsear directamente
                        try:
                            return json.loads(content.strip())
                        except json.JSONDecodeError:
                            pass
                        
                        # 2. Buscar bloques de c√≥digo JSON (```json ... ```)
                        json_pattern = r'```json\s*([\s\S]*?)\s*```'
                        json_match = re.search(json_pattern, content, re.IGNORECASE)
                        if json_match:
                            try:
                                extracted_json = json_match.group(1).strip()
                                parsed = json.loads(extracted_json)
                                # Si el JSON tiene un wrapper como "book_architecture", extraerlo
                                if isinstance(parsed, dict) and len(parsed) == 1:
                                    wrapper_key = list(parsed.keys())[0]
                                    if 'architecture' in wrapper_key.lower() or 'book' in wrapper_key.lower():
                                        return parsed[wrapper_key]
                                return parsed
                            except json.JSONDecodeError:
                                pass
                        
                        # 3. Buscar cualquier objeto JSON v√°lido (empiece con { y termine con })
                        brace_pattern = r'\{.*\}'
                        brace_match = re.search(brace_pattern, content, re.DOTALL)
                        if brace_match:
                            try:
                                json_text = brace_match.group(0)
                                return json.loads(json_text)
                            except json.JSONDecodeError:
                                pass
                        
                        # 4. Si todo falla, retornar None para manejar el error
                        return None
                    
                    architecture = extract_json_from_response(complete_content)
                    
                    if architecture is None:
                        # Si no se pudo extraer JSON v√°lido, crear estructura m√≠nima
                        logger.error("failed_to_parse_architecture_json",
                                   book_id=book_id,
                                   content_preview=complete_content[:500],
                                   content_length=len(complete_content))
                        
                        # Intentar extraer informaci√≥n b√°sica del texto
                        lines = complete_content.split('\n')
                        title_line = next((line for line in lines if 'title' in line.lower()), "")
                        
                        architecture = {
                            "title": book_params.get('title', 'Untitled Book'),
                            "summary": "Error parsing JSON response from Claude",
                            "target_pages": book_params.get('page_count', 50),
                            "estimated_words": book_params.get('page_count', 50) * 300,
                            "genre": book_params.get('genre', 'General'),
                            "tone": book_params.get('tone', 'Informative'),
                            "target_audience": book_params.get('target_audience', 'General'),
                            "language": book_params.get('language', 'es'),
                            "page_size": book_params.get('format_size', 'pocket'),
                            "line_spacing": book_params.get('line_spacing', 'medium'),
                            "chapter_count": book_params.get('chapter_count', 8),
                            "writing_style": book_params.get('writing_style', 'Professional'),
                            "include_toc": book_params.get('include_toc', True),
                            "include_introduction": book_params.get('include_introduction', True),
                            "include_conclusion": book_params.get('include_conclusion', True),
                            "structure": {
                                "introduction": {
                                    "title": "Introducci√≥n",
                                    "summary": "Introducci√≥n al tema del libro",
                                    "estimated_pages": 3
                                },
                                "chapters": [
                                    {
                                        "number": i,
                                        "title": f"Cap√≠tulo {i}: Contenido Principal {i}",
                                        "summary": f"Desarrollo del tema principal - parte {i}",
                                        "key_points": ["Punto clave 1", "Punto clave 2", "Punto clave 3"],
                                        "estimated_pages": max(4, (book_params.get('page_count', 50) - 6) // book_params.get('chapter_count', 8)),
                                        "learning_objectives": [f"Objetivo de aprendizaje {i}"]
                                    }
                                    for i in range(1, book_params.get('chapter_count', 8) + 1)
                                ],
                                "conclusion": {
                                    "title": "Conclusi√≥n",
                                    "summary": "Resumen y reflexiones finales",
                                    "estimated_pages": 3
                                }
                            },
                            "characters": [],
                            "key_themes": ["Tema principal"],
                            "writing_approach": "Enfoque directo y pr√°ctico",
                            "special_sections": [],
                            "additional_instructions": book_params.get('additional_instructions', ''),
                            "raw_content": complete_content,
                            "parsing_error": True
                        }
                    
                    emit_generation_log(book_id, 'success', 
                        f'Arquitectura del libro generada exitosamente')
                    
                    logger.info("architecture_generation_completed",
                               book_id=book_id,
                               architecture_length=len(complete_content),
                               thinking_length=len(complete_thinking),
                               tokens_used=final_message.usage.input_tokens + final_message.usage.output_tokens)
                    
                    # Debug thinking tokens - usar estimaci√≥n si API no reporta
                    thinking_tokens = getattr(final_message.usage, 'thinking_tokens', 0)
                    if thinking_tokens == 0 and complete_thinking:
                        thinking_tokens = self.estimate_thinking_tokens(complete_thinking)
                    logger.info("claude_usage_debug", 
                               book_id=book_id,
                               prompt_tokens=final_message.usage.input_tokens,
                               completion_tokens=final_message.usage.output_tokens,
                               thinking_tokens=thinking_tokens,
                               usage_attributes=dir(final_message.usage))
                    
                    return {
                        'architecture': architecture,
                        'thinking': complete_thinking,
                        'usage': {
                            'prompt_tokens': final_message.usage.input_tokens,
                            'completion_tokens': final_message.usage.output_tokens,
                            'thinking_tokens': thinking_tokens,
                            'total_tokens': final_message.usage.input_tokens + final_message.usage.output_tokens + thinking_tokens
                        },
                        'model': final_message.model,
                        'stop_reason': final_message.stop_reason
                    }
                
        except asyncio.TimeoutError:
            error_msg = f"Timeout generando arquitectura despu√©s de {self.architecture_timeout}s"
            logger.error("architecture_generation_timeout",
                        book_id=book_id,
                        timeout=self.architecture_timeout,
                        error=error_msg)
            
            # Track API call failure
            api_duration = time.time() - api_start_time if 'api_start_time' in locals() else 0
            track_claude_api_call(book_id, 'architecture_generation', api_duration,
                                0, 'timeout', self.model)
            
            # Track generation completion with error
            track_generation_complete(book_id, book_params.get('user_id', 0), 'timeout',
                                    0, 0, 0, error_msg)
            
            self._handle_api_error(Exception(error_msg))
            
            from app.routes.websocket import emit_generation_log
            emit_generation_log(book_id, 'error', error_msg)
            
            raise Exception(error_msg)
            
        except (APIError, APIConnectionError, RateLimitError) as e:
            error_msg = f"Error de Claude API: {str(e)}"
            logger.error("claude_api_error",
                        book_id=book_id,
                        error_type=type(e).__name__,
                        error=str(e))
            
            # Track API call failure
            api_duration = time.time() - api_start_time if 'api_start_time' in locals() else 0
            track_claude_api_call(book_id, 'architecture_generation', api_duration,
                                0, f'api_error_{type(e).__name__}', self.model)
            
            # Track generation completion with error
            track_generation_complete(book_id, book_params.get('user_id', 0), 'api_error',
                                    0, 0, 0, error_msg)
            
            self._handle_api_error(e)
            
            from app.routes.websocket import emit_generation_log
            emit_generation_log(book_id, 'error', error_msg)
            
            raise Exception(error_msg)
            
        except Exception as e:
            error_msg = f"Error inesperado generando arquitectura: {str(e)}"
            logger.error("architecture_generation_error",
                        book_id=book_id,
                        error=str(e),
                        error_type=type(e).__name__)
            
            # Track API call failure
            api_duration = time.time() - api_start_time if 'api_start_time' in locals() else 0
            track_claude_api_call(book_id, 'architecture_generation', api_duration,
                                0, f'unexpected_error', self.model)
            
            # Track generation completion with error
            track_generation_complete(book_id, book_params.get('user_id', 0), 'error',
                                    0, 0, 0, error_msg)
            
            self._handle_api_error(e)
            
            from app.routes.websocket import emit_generation_log
            emit_generation_log(book_id, 'error', error_msg)
            
            raise Exception(error_msg)
    
    # =====================================
    # M√âTODOS DE GENERACI√ìN DE ARQUITECTURA
    # =====================================
    
    def _build_architecture_messages(self, book_params: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Construye los mensajes para generar √∫nicamente la arquitectura del libro"""
        system_prompt = self._build_architecture_system_prompt()
        user_prompt = self._build_architecture_user_prompt(book_params)
        
        return [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": user_prompt
                    }
                ]
            }
        ]
    
    def _build_architecture_system_prompt(self) -> str:
        """Sistema prompt optimizado para generaci√≥n de arquitectura √∫nicamente"""
        return """You are a professional book architect. Your job is to create a detailed book structure and architecture that the user can review and approve before full content generation.

üö® CRITICAL: Generate ONLY the book architecture, NOT the full content.

Your output must be a well-structured JSON with the following format (this is just an EXAMPLE - use the actual user configuration values):

```json
{
  "title": "[USE EXACT USER TITLE]",
  "summary": "Brief book description (2-3 sentences)",
  "target_pages": "[USE USER'S TARGET PAGES]",
  "estimated_words": "[CALCULATE BASED ON USER'S PAGE COUNT]",
  "genre": "[USE USER'S SELECTED GENRE]",
  "tone": "[USE USER'S SELECTED TONE]",
  "target_audience": "[USE USER'S SELECTED AUDIENCE]",
  "language": "[USE USER'S SELECTED LANGUAGE]",
  "page_size": "[USE USER'S SELECTED PAGE SIZE]",
  "line_spacing": "[USE USER'S SELECTED LINE SPACING]",
  "chapter_count": "[USE USER'S REQUESTED CHAPTER COUNT]",
  "writing_style": "[USE USER'S SELECTED WRITING STYLE]",
  "include_toc": "[USE USER'S TOC PREFERENCE]",
  "include_introduction": "[USE USER'S INTRODUCTION PREFERENCE]",
  "include_conclusion": "[USE USER'S CONCLUSION PREFERENCE]",
  "structure": {
    "introduction": {
      "title": "Introduction Title",
      "summary": "What this introduction will cover",
      "estimated_pages": 5
    },
    "chapters": [
      {
        "number": 1,
        "title": "Chapter Title",
        "summary": "Detailed summary of what this chapter will cover",
        "key_points": ["Point 1", "Point 2", "Point 3"],
        "estimated_pages": 12,
        "learning_objectives": ["What reader will learn"]
      }
    ],
    "conclusion": {
      "title": "Conclusion Title", 
      "summary": "What the conclusion will cover",
      "estimated_pages": 3
    }
  },
  "characters": [
    {
      "name": "Character Name",
      "role": "Character role/importance",
      "description": "Brief character description"
    }
  ],
  "key_themes": ["Theme 1", "Theme 2"],
  "writing_approach": "How the book will be written",
  "special_sections": [
    {
      "type": "exercises/examples/case_studies",
      "frequency": "per chapter/throughout book",
      "purpose": "Why included"
    }
  ],
  "additional_instructions": "[INCLUDE USER'S ADDITIONAL INSTRUCTIONS IF PROVIDED]"
}
```

üö® CRITICAL REQUIREMENTS:
- Use ALL the exact configuration values provided by the user (title, pages, genre, tone, audience, language, page size, line spacing, chapter count, writing style, etc.)
- DO NOT use the example values shown above - they are just placeholders
- ‚ö†Ô∏è **CRITICAL: Use EXACT field names as shown in the JSON schema above**:
  - For chapters: Use "number" (NOT "chapter_number") and "estimated_pages" (NOT "pages")
  - For introduction/conclusion: Use "estimated_pages" (NOT "pages")
  - These field names are MANDATORY for frontend compatibility
- Generate a detailed chapter-by-chapter breakdown
- Each chapter should have clear learning objectives and key points
- Estimate realistic page counts for each section that add up to the user's target
- Include characters (regardless of genre - they can be real people, case study subjects, examples, etc.)
- Suggest special sections (exercises, examples, etc.) if relevant to the genre and topic
- Make sure total estimated pages match the user's target
- Provide enough detail for user to understand the full book structure
- Respect all user preferences (TOC, introduction, conclusion, etc.)

üö® **CR√çTICO - OBLIGATORIEDAD DE P√ÅGINAS:**
- **PROMESA AL USUARIO**: El usuario ha seleccionado un rango espec√≠fico de p√°ginas y DEBEMOS cumplirlo
- **DISTRIBUCI√ìN OBLIGATORIA**: La suma EXACTA de todas las p√°ginas estimadas DEBE igualar el target del usuario
- **RESPONSABILIDAD**: Fallar en el targeting de p√°ginas = Romper la promesa comercial al cliente
- **C√ÅLCULO PRECISO**: Cada cap√≠tulo debe tener p√°ginas realistas que sumen EXACTAMENTE el total prometido
- **NO BAJO-ESTIMACI√ìN**: Es mejor sobrestimar ligeramente que subestimar p√°ginas
- **FORMATO ESPEC√çFICO**: Considerar que diferentes formatos (page_size + line_spacing) afectan el contenido real

DO NOT write any actual book content - only the detailed architecture and structure using the user's exact specifications."""

    def _build_architecture_user_prompt(self, book_params: Dict[str, Any]) -> str:
        """Construye el prompt del usuario para arquitectura √∫nicamente"""
        language_map = {
            'es': 'Spanish',
            'en': 'English', 
            'pt': 'Portuguese',
            'fr': 'French'
        }
        
        user_language = book_params.get('language', 'es')
        language_name = language_map.get(user_language, user_language)
        
        # Obtener informaci√≥n de formato - IMPORTANTE: page_count ya viene calculado con el algoritmo de p√°ginas efectivas
        page_size = book_params.get('page_size', book_params.get('format_size', 'pocket'))
        line_spacing = book_params.get('line_spacing', 'medium')
        page_count = book_params.get('page_count', 50)  # Este valor YA est√° calculado seg√∫n el algoritmo (base √ó factores)
        
        # Calcular palabras aproximadas por p√°gina seg√∫n formato (aumentado 1.5x para mayor contenido)
        words_per_page = {
            ('pocket', 'single'): 375,  ('pocket', 'medium'): 300,  ('pocket', 'double'): 225,
            ('A5', 'single'): 525,      ('A5', 'medium'): 420,      ('A5', 'double'): 315,
            ('B5', 'single'): 675,      ('B5', 'medium'): 540,      ('B5', 'double'): 405,
            ('letter', 'single'): 750,  ('letter', 'medium'): 600,  ('letter', 'double'): 450,
        }
        
        words_per_page_estimate = words_per_page.get((page_size, line_spacing), 400)
        total_words = page_count * words_per_page_estimate
        
        # Obtener par√°metros adicionales del libro
        parameters = book_params.get('parameters', {})
        length_option = parameters.get('length', 'medium')  # short/medium/long
        
        return f"""üö® CRITICAL: Create ONLY a detailed book ARCHITECTURE (structure/outline), NOT the actual book content!

**COMPLETE USER CONFIGURATION (use ALL these values in your JSON):**

üìö **BASIC INFORMATION:**
- Title: {book_params.get('title', 'Untitled Book')}
- Genre: {book_params.get('genre', 'General')}
- Target Audience: {book_params.get('target_audience', 'General audience')}
- Tone: {book_params.get('tone', 'Informative')}
- Writing Style: {book_params.get('writing_style', 'Professional and engaging')}
- Language: {language_name.upper()} (Code: {user_language})

üìñ **BOOK STRUCTURE:**
- Length Option Selected: {length_option.upper()} (user selected this range)
- Target Pages (calculated): {page_count} pages
- Estimated Total Words: {total_words:,} words
- Number of Chapters: {book_params.get('chapter_count', 10)} chapters
- Page Size Format: {page_size}
- Line Spacing: {line_spacing}
- Include Table of Contents: {book_params.get('include_toc', True)}
- Include Introduction: {book_params.get('include_introduction', True)} 
- Include Conclusion: {book_params.get('include_conclusion', True)}

üí° **CONTENT SPECIFICATIONS:**
- Key Topics/Description: {book_params.get('key_topics', 'As relevant to the title')}
- Additional Instructions: {book_params.get('additional_instructions', 'None')}

‚ö†Ô∏è **CRITICAL ARCHITECTURE REQUIREMENTS:**
1. Generate ONLY the book architecture/structure - NO actual book content
2. Create a JSON with chapter titles, summaries, and structure - NOT the chapters themselves
3. Use ALL the configuration values exactly as provided above
4. The JSON must include: title, summary, target_pages ({page_count}), estimated_words ({total_words:,}), genre, tone, target_audience, language, page_size ({page_size}), line_spacing ({line_spacing}), chapter_count ({book_params.get('chapter_count', 10)}), writing_style, include_toc, include_introduction, include_conclusion
5. Create exactly {book_params.get('chapter_count', 10)} chapters in the structure
6. üéØ **CRITICAL PAGE DISTRIBUTION**: The sum of ALL chapter pages + introduction pages + conclusion pages must EXACTLY equal {page_count} pages
7. All text in the architecture (titles, summaries, descriptions) must be in {language_name.upper()}

üö® **OBLIGATORIEDAD CR√çTICA - CUMPLIMIENTO DE P√ÅGINAS:**
- **PROMESA COMERCIAL**: El usuario pag√≥ por {page_count} p√°ginas espec√≠ficas con formato {page_size}/{line_spacing}
- **CONSECUENCIAS**: No cumplir = Cliente insatisfecho + Promesa rota + P√©rdida de confianza
- **TARGETING OBLIGATORIO**: CADA p√°gina estimada cuenta para el resultado final
- **PRECISI√ìN MATEM√ÅTICA**: Total debe ser EXACTAMENTE {page_count} p√°ginas, ni una m√°s ni una menos
- **RESPONSABILIDAD TOTAL**: Eres responsable de que la arquitectura permita cumplir esta promesa

üìä **PAGE DISTRIBUTION GUIDANCE (OBLIGATORIA):**
- **Total target: {page_count} p√°ginas (MANDATORIO - SIN EXCEPCIONES)**
- Introduction: 3-5% of total pages ({"2-3" if page_count < 100 else "3-5"} pages)
- Conclusion: 3-5% of total pages ({"2-3" if page_count < 100 else "3-5"} pages)  
- Chapters: Remaining pages distributed logically ({page_count - (3 if page_count < 100 else 5) - (3 if page_count < 100 else 5)} pages total for chapters)
- Average per chapter: ~{(page_count - (6 if page_count < 100 else 10)) // book_params.get('chapter_count', 10)} pages, but vary based on content complexity
- **VERIFICACI√ìN**: Suma intro + chapters + conclusion = {page_count} p√°ginas EXACTAS

üõë **WHAT NOT TO DO:**
- Do NOT write actual chapter content
- Do NOT write paragraphs of book text
- Do NOT create the book itself
- ONLY create the structural outline/architecture in JSON format

Remember: You are creating a BLUEPRINT of the book, not writing the book itself.
- Structure should be appropriate for {book_params.get('genre', 'General')} genre
- Target a total of {book_params.get('page_count', 50)} pages
- Include {book_params.get('chapter_count', 10)} main chapters

Generate a comprehensive book architecture that the user can review, modify if needed, and approve before full content generation begins."""

    # =====================================
    # M√âTODOS UTILITARIOS Y VALIDACI√ìN
    # =====================================
    
    
    def estimate_generation_time(self, book_params: Dict[str, Any]) -> int:
        """
        Estima el tiempo de generaci√≥n en segundos basado en los par√°metros del libro.
        
        Args:
            book_params: Par√°metros del libro
            
        Returns:
            Tiempo estimado en segundos
        """
        base_time = 60  # 1 minuto base
        page_count = book_params.get('page_count', 50)
        chapter_count = book_params.get('chapter_count', 10)
        
        # ~2 segundos por p√°gina + ~5 segundos por cap√≠tulo
        estimated_time = base_time + (page_count * 2) + (chapter_count * 5)
        
        # M√°ximo 10 minutos
        return min(estimated_time, 600)
    
    def validate_book_params(self, book_params: Dict[str, Any]) -> Dict[str, Any]:
        """
        Valida y normaliza los par√°metros del libro.
        
        Args:
            book_params: Par√°metros del libro
            
        Returns:
            Par√°metros validados y normalizados
        """
        validated = book_params.copy()
        
        # Valores por defecto
        defaults = {
            'title': 'Libro Sin T√≠tulo',
            'genre': 'General',
            'target_audience': 'Audiencia general',
            'language': 'Spanish',
            'chapter_count': 10,
            'page_count': 50,
            'writing_style': 'Profesional y ameno',
            'tone': 'Informativo',
            'key_topics': 'Relevantes al t√≠tulo',
            'additional_instructions': 'Ninguna'
        }
        
        # Aplicar valores por defecto SOLO si el par√°metro no existe o es None
        for key, default_value in defaults.items():
            if key not in validated or validated[key] is None:
                validated[key] = default_value
        
        # Validar rangos
        validated['chapter_count'] = max(3, min(validated['chapter_count'], 20))
        validated['page_count'] = max(10, min(validated['page_count'], 300))
        
        # Normalizar strings
        string_fields = ['title', 'genre', 'target_audience', 'writing_style', 'tone']
        for field in string_fields:
            if field in validated and isinstance(validated[field], str):
                validated[field] = validated[field].strip()
        
        logger.info("book_params_validated",
                   title=validated['title'],
                   chapters=validated['chapter_count'],
                   pages=validated['page_count'])
        
        return validated

    # =====================================
    # M√âTODOS DE REGENERACI√ìN DE ARQUITECTURA
    # =====================================
    
    async def regenerate_book_architecture(self, book_id: int, book_params: Dict[str, Any], current_architecture: Dict[str, Any], feedback_what: str, feedback_how: str) -> Dict[str, Any]:
        """
        Regenera la arquitectura del libro basada en feedback espec√≠fico del usuario.
        
        Args:
            book_id: ID del libro
            book_params: Par√°metros originales del libro
            current_architecture: Arquitectura actual que se va a mejorar
            feedback_what: Qu√© no le gust√≥ al usuario de la arquitectura actual
            feedback_how: Qu√© cambios espec√≠ficos quiere el usuario
            
        Returns:
            Resultado con la arquitectura regenerada mejorada
        """
        try:
            # Log del inicio de regeneraci√≥n
            logger.info("starting_architecture_regeneration",
                       book_id=book_id,
                       has_current_architecture=bool(current_architecture),
                       feedback_what_length=len(feedback_what),
                       feedback_how_length=len(feedback_how))
                       
            # Preparar el prompt espec√≠fico para regeneraci√≥n con feedback
            messages = self._build_regeneration_messages(book_params, current_architecture, feedback_what, feedback_how)
            
            # Variables para acumular respuesta
            full_content = []
            thinking_content = []
            chunk_count = 0
            
            # Emisi√≥n de evento de inicio
            from app.routes.websocket import emit_book_progress_update, emit_generation_log
            
            emit_book_progress_update(book_id, {
                'current': 5,
                'total': 100,
                'status': 'connecting',
                'status_message': 'Conectando con Claude AI para regenerar arquitectura...',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            
            # Crear streaming request con thinking habilitado
            # Para regeneraci√≥n usamos tokens optimizados similar a arquitectura inicial
            regen_max_tokens = min(32000, self.max_tokens)  # Aumentado para arquitectura mejorada
            regen_budget_tokens = min(32000, self.thinking_budget)  # üß† Ampliado para regeneraci√≥n con thinking extendido
            
            async with self.client.messages.stream(
                model=self.model,
                max_tokens=regen_max_tokens,
                temperature=self.temperature,
                messages=messages,
                thinking={
                    "type": "enabled",
                    "budget_tokens": regen_budget_tokens
                },
            ) as stream:
                
                emit_book_progress_update(book_id, {
                    'current': 15,
                    'total': 100,
                    'status': 'thinking',
                    'status_message': 'Claude est√° analizando tu feedback y mejorando la arquitectura...',
                    'timestamp': datetime.now(timezone.utc).isoformat()
                })
                
                current_block_index = None
                
                async for event in stream:
                    chunk_count += 1
                    
                    # Thinking blocks
                    if event.type == "content_block_start" and event.content_block.type == "thinking":
                        current_block_index = event.index
                        emit_generation_log(book_id, 'thinking', 'Analizando feedback y replanteando arquitectura...')
                        
                    elif event.type == "content_block_delta" and hasattr(event, 'delta'):
                        # NUEVO: Thinking content via thinking_delta (regeneraci√≥n)
                        if hasattr(event.delta, 'type') and event.delta.type == "thinking_delta":
                            if hasattr(event.delta, 'thinking'):
                                thinking_content.append(event.delta.thinking)
                                if chunk_count % 50 == 0:
                                    emit_book_progress_update(book_id, {
                                        'current': 30,
                                        'total': 100,
                                        'status': 'thinking',
                                        'status_message': f'Refinando con feedback... ({len("".join(thinking_content))} chars thinking)',
                                        'timestamp': datetime.now(timezone.utc).isoformat()
                                    })
                        # Texto normal via text_delta 
                        elif hasattr(event.delta, 'text'):
                            text_chunk = event.delta.text
                            
                            # Si es contenido normal (no thinking)
                            if current_block_index is None or event.index != current_block_index:
                                full_content.append(text_chunk)
                            
                            # Content principal
                            else:
                                full_content.append(text_chunk)
                                
                                if chunk_count % 30 == 0:
                                    emit_book_progress_update(book_id, {
                                        'current': 50 + (chunk_count % 200) // 10,  # 50-70%
                                        'total': 100,
                                        'status': 'writing',
                                        'status_message': 'Generando arquitectura mejorada basada en tu feedback...',
                                        'timestamp': datetime.now(timezone.utc).isoformat()
                                    })
                    
                    elif event.type == "content_block_stop":
                        if current_block_index == event.index:
                            emit_generation_log(book_id, 'thinking', 'An√°lisis de feedback completado')
                            current_block_index = None
                        else:
                            emit_book_progress_update(book_id, {
                                'current': 90,
                                'total': 100,
                                'status': 'finalizing',
                                'status_message': 'Finalizando arquitectura regenerada...',
                                'timestamp': datetime.now(timezone.utc).isoformat()
                            })
                
                # Obtener mensaje final
                final_message = await stream.get_final_message()
                
                # Parsear la arquitectura regenerada
                complete_content = ''.join(full_content)
                complete_thinking = ''.join(thinking_content)
                
                # Intentar parsear como JSON, si falla mantener como texto
                try:
                    import json
                    architecture = json.loads(complete_content)
                    
                    # Validar que la arquitectura regenerada tenga la estructura m√≠nima requerida
                    if not architecture.get('structure') or not architecture.get('structure', {}).get('chapters'):
                        logger.warning("regenerated_architecture_incomplete", book_id=book_id)
                        # Intentar usar la arquitectura actual con mejoras textuales
                        architecture = current_architecture.copy()
                        architecture['regeneration_notes'] = complete_content
                        architecture['feedback_incorporated'] = True
                        
                        # BACKEND ONLY: Parsear personajes y secciones especiales del Markdown
                        parsed_elements = self._parse_markdown_architecture_elements(complete_content, book_params)
                        if parsed_elements['characters']:
                            architecture['characters'] = parsed_elements['characters']
                            logger.info("extracted_characters_from_incomplete_json", 
                                       book_id=book_id, 
                                       count=len(parsed_elements['characters']))
                        if parsed_elements['special_sections']:
                            architecture['special_sections'] = parsed_elements['special_sections']
                            logger.info("extracted_special_sections_from_incomplete_json", 
                                       book_id=book_id, 
                                       count=len(parsed_elements['special_sections']))
                        
                except json.JSONDecodeError:
                    logger.warning("regenerated_architecture_json_error", book_id=book_id)
                    # Si no es JSON v√°lido, usar la arquitectura actual como base
                    architecture = current_architecture.copy()
                    architecture['regeneration_content'] = complete_content
                    architecture['feedback_incorporated'] = True
                    architecture['regeneration_method'] = 'text_based'
                    
                    # BACKEND ONLY: Parsear personajes y secciones especiales del Markdown
                    parsed_elements = self._parse_markdown_architecture_elements(complete_content, book_params)
                    if parsed_elements['characters']:
                        architecture['characters'] = parsed_elements['characters']
                        logger.info("extracted_characters_from_markdown", 
                                   book_id=book_id, 
                                   count=len(parsed_elements['characters']))
                    if parsed_elements['special_sections']:
                        architecture['special_sections'] = parsed_elements['special_sections']
                        logger.info("extracted_special_sections_from_markdown", 
                                   book_id=book_id, 
                                   count=len(parsed_elements['special_sections']))
                
                # Marcar que es una regeneraci√≥n
                architecture['regenerated'] = True
                architecture['regeneration_timestamp'] = datetime.now(timezone.utc).isoformat()
                architecture['user_feedback'] = {
                    'what_disliked': feedback_what,
                    'requested_changes': feedback_how
                }
                
                emit_generation_log(book_id, 'success', 
                    f'Arquitectura regenerada exitosamente basada en tu feedback')
                
                logger.info("architecture_regeneration_completed",
                           book_id=book_id,
                           architecture_length=len(complete_content),
                           thinking_length=len(complete_thinking),
                           feedback_incorporated=True)
                
                # Debug thinking tokens for regeneration - usar estimaci√≥n si API no reporta
                thinking_tokens = getattr(final_message.usage, 'thinking_tokens', 0)
                if thinking_tokens == 0 and complete_thinking:
                    thinking_tokens = self.estimate_thinking_tokens(complete_thinking)
                logger.info("claude_regeneration_usage_debug", 
                           book_id=book_id,
                           prompt_tokens=final_message.usage.input_tokens,
                           completion_tokens=final_message.usage.output_tokens,
                           thinking_tokens=thinking_tokens,
                           usage_attributes=dir(final_message.usage))
                
                return {
                    'architecture': architecture,
                    'thinking': complete_thinking,
                    'usage': {
                        'prompt_tokens': final_message.usage.input_tokens,
                        'completion_tokens': final_message.usage.output_tokens,
                        'thinking_tokens': thinking_tokens,
                        'total_tokens': final_message.usage.input_tokens + final_message.usage.output_tokens + thinking_tokens
                    },
                    'model': final_message.model,
                    'stop_reason': final_message.stop_reason,
                    'regenerated': True
                }
                
        except Exception as e:
            logger.error(f"Architecture regeneration error: {str(e)}")
            
            from app.routes.websocket import emit_generation_log
            emit_generation_log(book_id, 'error', f'Error regenerando arquitectura: {str(e)}')
            
            raise

    # =====================================
    # M√âTODOS DE SOPORTE PARA REGENERACI√ìN DE ARQUITECTURA
    # =====================================
    
    def _build_regeneration_messages(self, book_params: Dict[str, Any], current_architecture: Dict[str, Any], feedback_what: str, feedback_how: str) -> List[Dict[str, Any]]:
        """Construye los mensajes para regenerar arquitectura con feedback del usuario"""
        system_prompt = self._build_regeneration_system_prompt()
        user_prompt = self._build_regeneration_user_prompt(book_params, current_architecture, feedback_what, feedback_how)
        
        return [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": user_prompt
                    }
                ]
            }
        ]

    def _build_regeneration_system_prompt(self) -> str:
        """Sistema prompt para regeneraci√≥n de arquitectura con feedback"""
        return """You are a professional book architect specialized in improving book structures based on user feedback.

üö® CRITICAL: You must regenerate the book architecture incorporating the user's specific feedback while maintaining professional quality.

Your output must be a well-structured JSON with the same format as before, but improved based on the feedback.

‚ö†Ô∏è IMPORTANT: The following JSON is just an EXAMPLE TEMPLATE - DO NOT use these example values:

```json
{
  "title": "[KEEP ORIGINAL TITLE OR IMPROVE BASED ON FEEDBACK]",
  "summary": "[IMPROVED BOOK DESCRIPTION BASED ON FEEDBACK]",
  "target_pages": "[USE ACTUAL TARGET PAGES FROM USER CONFIG]",
  "estimated_words": "[CALCULATE BASED ON ACTUAL USER SPECIFICATIONS]",
  "genre": "[USE ACTUAL GENRE FROM USER CONFIG]",
  "tone": "[USE ORIGINAL TONE OR ADJUST IF FEEDBACK SUGGESTS]",
  "target_audience": "[USE ACTUAL AUDIENCE FROM USER CONFIG]",
  "language": "[USE ACTUAL LANGUAGE FROM USER CONFIG]",
  "page_size": "[USE ACTUAL PAGE SIZE FROM USER CONFIG]",
  "line_spacing": "[USE ACTUAL LINE SPACING FROM USER CONFIG]",
  "chapter_count": "[USE ACTUAL CHAPTER COUNT FROM USER CONFIG]",
  "writing_style": "[USE ACTUAL WRITING STYLE OR IMPROVE BASED ON FEEDBACK]",
  "include_toc": "[USE ACTUAL TOC PREFERENCE]",
  "include_introduction": "[USE ACTUAL INTRODUCTION PREFERENCE]",
  "include_conclusion": "[USE ACTUAL CONCLUSION PREFERENCE]",
  "writing_approach": "[DESCRIBE IMPROVED APPROACH BASED ON FEEDBACK]",
  "structure": {
    "introduction": {
      "title": "[ACTUAL INTRODUCTION TITLE - IMPROVE IF NEEDED]",
      "summary": "[IMPROVED INTRODUCTION OUTLINE BASED ON FEEDBACK]",
      "estimated_pages": "[REALISTIC PAGE ESTIMATE]"
    },
    "chapters": [
      {
        "number": 1,
        "title": "[IMPROVED CHAPTER TITLE BASED ON FEEDBACK]",
        "summary": "[ENHANCED CHAPTER SUMMARY ADDRESSING FEEDBACK]",
        "key_points": ["[ACTUAL IMPROVED POINTS BASED ON FEEDBACK]"],
        "estimated_pages": "[REALISTIC PAGE ESTIMATE]",
        "learning_objectives": ["[ENHANCED OBJECTIVES BASED ON FEEDBACK]"]
      }
    ],
    "conclusion": {
      "title": "[ACTUAL CONCLUSION TITLE]", 
      "summary": "[IMPROVED CONCLUSION OUTLINE]",
      "estimated_pages": "[REALISTIC PAGE ESTIMATE]"
    }
  },
  "characters": [
    {
      "name": "[ACTUAL CHARACTER NAME OR NEW BASED ON FEEDBACK]",
      "role": "[ENHANCED CHARACTER ROLE BASED ON FEEDBACK]",
      "description": "[IMPROVED CHARACTER DESCRIPTION]"
    }
  ],
  "key_themes": ["[ACTUAL ENHANCED THEMES BASED ON FEEDBACK]"],
  "special_sections": [
    {
      "type": "[ACTUAL SECTION TYPE BASED ON FEEDBACK]",
      "frequency": "[ACTUAL FREQUENCY]",
      "purpose": "[ACTUAL PURPOSE BASED ON FEEDBACK]"
    }
  ],
  "improvements_made": ["[LIST SPECIFIC IMPROVEMENTS YOU MADE BASED ON USER FEEDBACK]"],
  "feedback_addressed": true
}
```

üö® CRITICAL REQUIREMENTS:
- The above JSON is ONLY an example template showing the structure
- DO NOT use any of the example values (150 pages, 45000 words, etc.)
- Use the ACTUAL configuration values from the user's book
- Use the ACTUAL current architecture as your starting point
- Incorporate ALL the user's specific feedback
- Make substantial improvements based on what the user requested
- ‚ö†Ô∏è **CRITICAL: Use EXACT field names as shown in the JSON schema above**:
  - For chapters: Use "number" (NOT "chapter_number") and "estimated_pages" (NOT "pages")
  - For introduction/conclusion: Use "estimated_pages" (NOT "pages")
  - These field names are MANDATORY for frontend compatibility

FEEDBACK INCORPORATION REQUIREMENTS:
- Carefully analyze what the user didn't like and address those specific issues
- Implement the exact changes the user requested
- Improve weak areas identified in the feedback
- Enhance sections the user wants expanded
- Adjust tone, structure, or content focus as requested
- Add missing elements the user identified
- Remove or modify elements the user found unnecessary
- Maintain overall coherence while making requested changes

QUALITY REQUIREMENTS:
- Ensure the regenerated architecture is better than the original
- Address all feedback points systematically
- Maintain professional structure and completeness
- Keep the same JSON format for consistency
- Ensure chapter count and page estimates remain realistic
- Preserve good elements from the original while improving problematic areas

üö® **OBLIGATORIEDAD CR√çTICA DE P√ÅGINAS (EN REGENERACI√ìN):**
- **MANTENER PROMESA**: El target de p√°ginas original DEBE mantenerse exacto
- **NO COMPROMETER**: Las mejoras NO pueden reducir el cumplimiento de p√°ginas
- **MEJOR DISTRIBUCI√ìN**: Mejorar c√≥mo se distribuyen las p√°ginas, no reducir el total
- **RESPONSABILIDAD TOTAL**: Una regeneraci√≥n que comprometa las p√°ginas = FALLO CR√çTICO
- **VERIFICACI√ìN OBLIGATORIA**: La nueva arquitectura DEBE sumar exactamente las mismas p√°ginas target

DO NOT simply make minor cosmetic changes - make substantial improvements based on the specific feedback provided."""

    def _build_regeneration_user_prompt(self, book_params: Dict[str, Any], current_architecture: Dict[str, Any], feedback_what: str, feedback_how: str) -> str:
        """Construye el prompt para regeneraci√≥n con feedback espec√≠fico"""
        language_map = {
            'es': 'Spanish',
            'en': 'English', 
            'pt': 'Portuguese',
            'fr': 'French'
        }
        
        user_language = book_params.get('language', 'es')
        language_name = language_map.get(user_language, user_language)
        
        # Serializar la arquitectura actual
        import json
        current_architecture_json = json.dumps(current_architecture, indent=2, ensure_ascii=False)
        
        # Obtener informaci√≥n de formato completa
        page_size = book_params.get('page_size', book_params.get('format_size', 'pocket'))
        line_spacing = book_params.get('line_spacing', 'medium')
        page_count = book_params.get('page_count', 50)
        
        # Calcular palabras aproximadas
        words_per_page = {
            ('pocket', 'single'): 375,  ('pocket', 'medium'): 300,  ('pocket', 'double'): 225,
            ('A5', 'single'): 525,      ('A5', 'medium'): 420,      ('A5', 'double'): 315,
            ('B5', 'single'): 675,      ('B5', 'medium'): 540,      ('B5', 'double'): 405,
            ('letter', 'single'): 750,  ('letter', 'medium'): 600,  ('letter', 'double'): 450,
        }
        words_per_page_estimate = words_per_page.get((page_size, line_spacing), 400)
        total_words = page_count * words_per_page_estimate
        
        return f"""Please regenerate the book architecture based on the user's specific feedback.

**üìö COMPLETE ORIGINAL BOOK SPECIFICATIONS:**
- Title: {book_params.get('title', 'Untitled Book')}
- Genre: {book_params.get('genre', 'General')}
- Target Audience: {book_params.get('target_audience', 'General audience')}
- Writing Style: {book_params.get('writing_style', 'Professional and engaging')}
- Tone: {book_params.get('tone', 'Informative')}
- Language: {language_name.upper()} (Code: {user_language})

**üìñ FORMAT SPECIFICATIONS:**
- Page Size: {page_size.upper()} format
- Line Spacing: {line_spacing}
- Target Pages: {page_count} pages
- Estimated Words: {total_words:,} words
- Number of Chapters: {book_params.get('chapter_count', 10)}

**üìã STRUCTURE PREFERENCES:**
- Include Table of Contents: {book_params.get('include_toc', True)}
- Include Introduction: {book_params.get('include_introduction', True)}
- Include Conclusion: {book_params.get('include_conclusion', True)}

**üí° CONTENT FOCUS:**
- Key Topics: {book_params.get('key_topics', 'As relevant to the title')}
- Additional Instructions: {book_params.get('additional_instructions', 'None')}

**CURRENT ARCHITECTURE (TO BE IMPROVED):**
```json
{current_architecture_json}
```

**USER FEEDBACK - CRITICAL REQUIREMENTS:**

**What the user DIDN'T LIKE about the current architecture:**
{feedback_what}

**What the user WANTS CHANGED or IMPROVED:**
{feedback_how}

**REGENERATION REQUIREMENTS:**
- Address EVERY point mentioned in the user's feedback
- Make substantial improvements, not just minor tweaks
- If user wants more chapters, add them with detailed content
- If user wants different themes, incorporate them thoroughly
- If user wants character changes, implement them completely
- If user wants tone adjustments, reflect them throughout
- If user wants structural changes, rebuild the structure accordingly
- Maintain {language_name.upper()} language throughout
- Keep the target of {book_params.get('page_count', 50)} pages total
- Ensure the regenerated architecture is significantly better than the original

**FEEDBACK INCORPORATION CHECKLIST:**
- ‚úÖ Analyze each feedback point systematically
- ‚úÖ Address what the user didn't like by changing or removing those elements
- ‚úÖ Implement the specific improvements the user requested
- ‚úÖ Enhance weak areas identified in the feedback
- ‚úÖ Add missing elements the user identified
- ‚úÖ Adjust chapter structure if requested
- ‚úÖ Modify character development if mentioned
- ‚úÖ Update special sections based on feedback
- ‚úÖ Improve writing approach or tone as suggested

**QUALITY ASSURANCE:**
- The new architecture must be noticeably better than the original
- Every aspect mentioned in the feedback must be addressed
- The result should align perfectly with the user's vision
- Maintain professional quality and structure throughout

üö® **OBLIGATORIEDAD CR√çTICA DE P√ÅGINAS (REGENERACI√ìN):**
- **COMPROMISO COMERCIAL**: Las {page_count} p√°ginas prometidas son INEGOCIABLES
- **NO REDUCIR**: El feedback NO puede ser excusa para reducir p√°ginas
- **MEJORAR DISTRIBUCI√ìN**: Redistribuir mejor las p√°ginas entre cap√≠tulos
- **VERIFICACI√ìN FINAL**: Nueva arquitectura DEBE sumar EXACTAMENTE {page_count} p√°ginas
- **RESPONSABILIDAD**: Fallar en el targeting = Romper promesa al cliente pagador

Generate the improved architecture in {language_name.upper()} that fully incorporates the user's feedback and creates a superior book structure."""


    # =====================================
    # M√âTODOS DE REGENERACI√ìN DE CAP√çTULOS
    # =====================================
    
    async def regenerate_chapter_content(self, chapter_content: str, feedback: Dict[str, str], book=None) -> Dict[str, Any]:
        """
        Regenera un cap√≠tulo espec√≠fico basado en el feedback del usuario.
        
        Args:
            chapter_content: Contenido actual del cap√≠tulo
            feedback: Diccionario con whatDislike, whatChange, howWant
            book: Objeto del libro (opcional) para calcular palabras basado en arquitectura
            
        Returns:
            Dict con el nuevo contenido y m√©tricas de uso
        """
        try:
            # Preparar el prompt para regeneraci√≥n de cap√≠tulo
            messages = self._build_chapter_regeneration_messages(chapter_content, feedback, book)
            
            logger.info("starting_chapter_regeneration", 
                       content_length=len(chapter_content),
                       feedback_keys=list(feedback.keys()))
            
            # Llamar a Claude con configuraci√≥n espec√≠fica para regeneraci√≥n
            system_prompt = self._build_chapter_regeneration_system_prompt()
            user_prompt = self._build_chapter_regeneration_user_prompt(chapter_content, feedback, book)
            
            # Para regeneraci√≥n de cap√≠tulos, necesitamos m√°s tokens para cap√≠tulos m√°s extensos
            chapter_max_tokens = 32000  # Aumentado para cap√≠tulos muy extensos
            chapter_budget_tokens = min(34000, self.thinking_budget)  # üß† Ampliado para regeneraci√≥n de cap√≠tulos con thinking profundo
            
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=chapter_max_tokens,  # Aumentado para contenido extenso
                temperature=0.7,  # Creatividad controlada
                system=system_prompt,
                messages=[{
                    "role": "user",
                    "content": user_prompt
                }],
                thinking={
                    "type": "enabled",
                    "budget_tokens": chapter_budget_tokens  # Ahora < max_tokens
                },
            )
            
            # Extraer contenido y thinking
            content = ""
            thinking_content = ""
            
            for block in response.content:
                if hasattr(block, 'text'):
                    content += block.text
                elif hasattr(block, 'type') and block.type == 'thinking':
                    thinking_content += getattr(block, 'text', '')
            
            # M√©tricas de uso
            thinking_tokens = getattr(response.usage, 'thinking_tokens', 0) if hasattr(response, 'usage') else 0
            usage_info = {
                'prompt_tokens': response.usage.input_tokens if hasattr(response, 'usage') else 0,
                'completion_tokens': response.usage.output_tokens if hasattr(response, 'usage') else 0,
                'thinking_tokens': thinking_tokens,
                'total_tokens': (response.usage.input_tokens + response.usage.output_tokens + thinking_tokens) if hasattr(response, 'usage') else 0
            }
            
            logger.info("chapter_regeneration_completed",
                       new_content_length=len(content),
                       **usage_info)
            
            return {
                'content': content.strip(),
                'thinking': thinking_content,
                'usage': usage_info,
                'success': True
            }
            
        except Exception as e:
            logger.error("chapter_regeneration_failed", error=str(e))
            return {
                'content': '',
                'usage': {},
                'success': False,
                'error': str(e)
            }
    
    # =====================================
    # NUEVO: GENERACI√ìN MULTI-CHUNKED CON CLAUDE SONNET 4
    # =====================================
    
    async def generate_book_from_architecture_multichunk(self, book_id: int, book_params: Dict[str, Any], approved_architecture: Dict[str, Any]) -> Dict[str, Any]:
        """
        Genera el contenido completo del libro usando generaci√≥n multi-chunked con Claude Sonnet 4.
        Garantiza que se cumplan las p√°ginas prometidas al usuario.
        
        Args:
            book_id: ID del libro
            book_params: Par√°metros originales del libro
            approved_architecture: Arquitectura aprobada por el usuario
            
        Returns:
            Resultado de la generaci√≥n con contenido completo
        """
        try:
            # Log cr√≠tico del inicio con Claude Sonnet 4
            logger.info("starting_multichunk_generation",
                       book_id=book_id,
                       model=self.model,
                       chapters_count=len(approved_architecture.get('structure', {}).get('chapters', [])),
                       target_pages=approved_architecture.get('target_pages'),
                       estimated_words=approved_architecture.get('estimated_words'),
                       max_tokens_per_chunk=self.max_tokens,
                       max_chunks=self.max_chunks)
            
            # Emisi√≥n de evento de inicio
            from app.routes.websocket import emit_book_progress_update, emit_generation_log
            
            emit_book_progress_update(book_id, {
                'current': 5,
                'total': 100,
                'status': 'initializing',
                'status_message': 'Iniciando generaci√≥n multi-chunked con Claude Sonnet 4...',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            
            # Dividir cap√≠tulos en chunks
            chapters = approved_architecture.get('structure', {}).get('chapters', [])
            total_chapters = len(chapters)
            
            if total_chapters == 0:
                raise Exception("No se encontraron cap√≠tulos en la arquitectura")
            
            # üöÄ OPTIMIZACI√ìN: Balance PERFECTO entre VELOCIDAD y TARGETING PRECISO DE P√ÅGINAS
            # Calcular chunks necesarios (3-4 cap√≠tulos por chunk - √≥ptimo para control de p√°ginas)
            chapters_per_chunk = max(3, min(4, total_chapters // max(1, self.max_chunks - 1) + 1))
            chunks = []
            
            for i in range(0, total_chapters, chapters_per_chunk):
                chunk_chapters = chapters[i:i + chapters_per_chunk]
                chunks.append({
                    'index': len(chunks) + 1,
                    'chapters': chunk_chapters,
                    'start_chapter': i + 1,
                    'end_chapter': min(i + chapters_per_chunk, total_chapters)
                })
            
            logger.info("chunk_planning",
                       book_id=book_id,
                       total_chunks=len(chunks),
                       chapters_per_chunk=chapters_per_chunk,
                       total_chapters=total_chapters)
            
            # Variables de acumulaci√≥n
            complete_book_content = []
            complete_thinking_content = []
            total_tokens_used = 0
            total_thinking_tokens = 0
            total_prompt_tokens = 0
            total_completion_tokens = 0
            chunk_summaries = []
            
            # üö® SISTEMA DE COHERENCIA: Basado en arquitectura aprobada con formato espec√≠fico
            
            # Obtener coherence manager configurado para este libro espec√≠fico
            coherence_manager = self._get_coherence_manager_for_book(book_params)
            
            # 1. Extraer target real de la arquitectura
            target_pages = coherence_manager.extract_target_pages_from_architecture(
                approved_architecture, book_params
            )
            
            # 2. Validar y estructurar cap√≠tulos con p√°ginas target
            structured_chapters = coherence_manager.validate_and_structure_chapters(
                approved_architecture, target_pages
            )
            
            # 3. Calcular distribuci√≥n coherente por chunks
            chunk_distributions = coherence_manager.calculate_chunk_page_distribution(
                structured_chapters, target_pages
            )
            
            # üö® VALIDACI√ìN CR√çTICA: Verificar que se generaron distribuciones de chunks
            if not chunk_distributions:
                raise Exception(f"No se pudieron generar distribuciones de chunks. Structured chapters: {len(structured_chapters)}, Target pages: {target_pages}")
            
            logger.info("coherence_system_initialized",
                       book_id=book_id,
                       target_pages=target_pages,
                       structured_chapters=len(structured_chapters),
                       planned_chunks=len(chunk_distributions))
            
            chunk_num = 0
            max_total_chunks = 4  # üöÄ OPTIMIZADO: 3 principales + 1 adicional m√°ximo para VELOCIDAD
            generated_chapters = []  # Track cap√≠tulos generados
            
            # üìñ GENERAR INTRODUCCI√ìN (si est√° configurada)
            emit_book_progress_update(book_id, {
                'current': 8,
                'total': 100,
                'status': 'generating_introduction',
                'status_message': 'Generando introducci√≥n personalizada del libro...',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            
            introduction_result = await self._generate_introduction(book_id, book_params, approved_architecture)
            if introduction_result['content']:
                complete_book_content.append(introduction_result['content'])
                complete_thinking_content.append(introduction_result['thinking'])
                total_tokens_used += introduction_result['usage']['total_tokens']
                total_thinking_tokens += introduction_result['usage']['thinking_tokens']
                # Introduction doesn't have separate prompt/completion tracking yet, but add placeholders
                total_prompt_tokens += introduction_result['usage'].get('prompt_tokens', 0)
                total_completion_tokens += introduction_result['usage'].get('completion_tokens', 0)
                
                emit_generation_log(book_id, 'success', 
                    f'‚úÖ Introducci√≥n generada: {len(introduction_result["content"].split())} palabras')
            
            # üöÄ PARALELIZACI√ìN DE CHUNKS - OPTIMIZACI√ìN M√ÅXIMO IMPACTO
            # Reducir de 45-60 min (secuencial) ‚Üí 15-20 min (paralelo)
            
            emit_book_progress_update(book_id, {
                'current': 15,
                'total': 100,
                'status': 'preparing_parallel_generation',
                'status_message': f'üöÄ Preparando generaci√≥n paralela de {len(chunk_distributions)} chunks principales...',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            
            # Preparar tareas paralelas para chunks principales
            chunk_tasks = []
            for chunk_idx, chunk_distribution in enumerate(chunk_distributions):
                chunk_num = chunk_idx + 1
                
                # Preparar chunk info con distribuci√≥n coherente
                coherent_chunk_info = {
                    'index': chunk_num,
                    'chapters': chunk_distribution['chapters'],
                    'target_pages': chunk_distribution['target_pages'],
                    'target_words': chunk_distribution['target_words'],
                    'start_chapter': chunk_distribution['start_chapter'],
                    'end_chapter': chunk_distribution['end_chapter']
                }
                
                # Crear tarea para generaci√≥n paralela
                task = self._generate_chunk_parallel(
                    book_id=book_id,
                    chunk_info=coherent_chunk_info,
                    book_params=book_params,
                    approved_architecture=approved_architecture,
                    introduction_content=complete_book_content[0] if complete_book_content else "",
                    chunk_idx=chunk_idx
                )
                chunk_tasks.append(task)
            
            # üöÄ EJECUTAR CHUNKS EN PARALELO - M√ÅXIMA OPTIMIZACI√ìN
            emit_book_progress_update(book_id, {
                'current': 20,
                'total': 100,
                'status': 'generating_parallel_chunks',
                'status_message': f'üöÄ Generando {len(chunk_distributions)} chunks principales EN PARALELO...',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            
            emit_generation_log(book_id, 'info', 
                f'üöÄ PARALELIZACI√ìN ACTIVA: Generando {len(chunk_distributions)} chunks simult√°neamente')
            
            # Esperar todos los chunks en paralelo
            chunk_results = await asyncio.gather(*chunk_tasks, return_exceptions=True)
            
            # üöÄ PROCESAMIENTO OPTIMIZADO: Sin validaciones costosas intermedias
            emit_generation_log(book_id, 'success', 
                f'‚úÖ Paralelizaci√≥n completada: {len(chunk_results)} chunks generados simult√°neamente')
            
            # Procesar resultados paralelos manteniendo orden correcto
            for idx, chunk_result in enumerate(chunk_results):
                if isinstance(chunk_result, Exception):
                    emit_generation_log(book_id, 'error', 
                        f'‚ùå Error en chunk paralelo {idx + 1}: {str(chunk_result)}')
                    raise chunk_result
                
                # Acumular resultados directamente (sin validaciones costosas)
                complete_book_content.append(chunk_result['content'])
                complete_thinking_content.append(chunk_result['thinking'])
                total_tokens_used += chunk_result['usage']['total_tokens']
                total_thinking_tokens += chunk_result['usage']['thinking_tokens']
                total_prompt_tokens += chunk_result['usage'].get('prompt_tokens', 0)
                total_completion_tokens += chunk_result['usage'].get('completion_tokens', 0)
                
                emit_generation_log(book_id, 'success', 
                    f'‚úÖ Chunk {idx + 1} integrado: {len(chunk_result["content"].split())} palabras')
            
            # üöÄ OPTIMIZACI√ìN: Progreso consolidado tras paralelizaci√≥n
            emit_book_progress_update(book_id, {
                'current': 70,
                'total': 100,
                'status': 'parallel_chunks_completed',
                'status_message': f'Chunks principales completados en paralelo - Evaluando contenido...',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            
            # üöÄ ELIMINACI√ìN TOTAL DEL BUCLE WHILE - ESTRATEGIA PREDETERMINISTA
            # Calcular si necesitamos chunks adicionales basado en d√©ficit actual
            current_content = '\n\n'.join(complete_book_content)
            current_words = len(current_content.split())
            current_pages = current_words // 350
            pages_ratio = current_pages / target_pages if target_pages > 0 else 1
            
            emit_generation_log(book_id, 'info', 
                f'üìä Evaluaci√≥n inicial: {current_pages}/{target_pages} p√°ginas ({pages_ratio:.1%})')
            
            # üéØ ESTRATEGIA DETERMIN√çSTICA: M√°ximo 1 chunk adicional si es absolutamente necesario
            additional_chunks_needed = 0
            if pages_ratio < 0.70:  # Solo si tenemos menos del 70%
                pages_deficit = target_pages - current_pages
                additional_chunks_needed = 1 if pages_deficit > 15 else 0  # Solo 1 chunk extra m√°ximo
                
                emit_generation_log(book_id, 'info', 
                    f'üìà D√©ficit detectado: {pages_deficit} p√°ginas faltantes - Generando 1 chunk adicional')
            else:
                emit_generation_log(book_id, 'success', 
                    f'‚úÖ Target suficiente alcanzado: {current_pages} p√°ginas ({pages_ratio:.1%}) - Sin chunks adicionales')
            
            # Generar chunk adicional SOLO si es absolutamente necesario
            if additional_chunks_needed > 0 and chunk_num < max_total_chunks:
                
                # Generar estrategia de continuaci√≥n inteligente
                continuation_strategy = coherence_manager.generate_continuation_strategy(
                    current_pages, target_pages, generated_chapters
                )
                
                # Generar chunk de continuaci√≥n
                chunk_num += 1
                progress_base = 70 + ((chunk_num - len(chunk_distributions)) * 20 // (max_total_chunks - len(chunk_distributions)))
                
                emit_book_progress_update(book_id, {
                    'current': progress_base,
                    'total': 100,
                    'status': 'extending_content',
                    'status_message': f'Estrategia: {continuation_strategy["type"]} - Chunk {chunk_num} ({continuation_strategy["pages_deficit"]} p√°ginas faltantes)...',
                    'timestamp': datetime.now(timezone.utc).isoformat()
                })
                
                # Crear chunk de continuaci√≥n inteligente
                continuation_chunk = {
                    'index': chunk_num,
                    'chapters': [],
                    'start_chapter': 'continuaci√≥n',
                    'end_chapter': 'continuaci√≥n',
                    'is_continuation': True,
                    'continuation_strategy': continuation_strategy,
                    'target_pages_remaining': continuation_strategy['pages_deficit'],
                    'target_words_remaining': continuation_strategy['target_words'],
                    'generated_chapters': generated_chapters.copy()
                }
                
                emit_generation_log(book_id, 'info', 
                    f'üîÑ Continuaci√≥n {chunk_num}: {continuation_strategy["strategy"]}')
                
                # Generar contenido de continuaci√≥n
                chunk_result = await self._generate_single_chunk(
                    book_id=book_id,
                    chunk_info=continuation_chunk,
                    book_params=book_params,
                    approved_architecture=approved_architecture,
                    previous_content=current_content,
                    chunk_summaries=chunk_summaries,
                    progress_base=progress_base
                )
                
                # Acumular resultados
                complete_book_content.append(chunk_result['content'])
                complete_thinking_content.append(chunk_result['thinking'])
                total_tokens_used += chunk_result['usage']['total_tokens']
                total_thinking_tokens += chunk_result['usage']['thinking_tokens']
                total_prompt_tokens += chunk_result['usage'].get('prompt_tokens', 0)
                total_completion_tokens += chunk_result['usage'].get('completion_tokens', 0)
                
                # Guardar resumen para contexto
                chunk_summaries.append({
                    'chunk_number': chunk_num,
                    'chapters': 'continuaci√≥n',
                    'word_count': len(chunk_result['content'].split()),
                    'summary': chunk_result['content'][:500] + "..." if len(chunk_result['content']) > 500 else chunk_result['content']
                })
                
                # Verificar progreso
                new_content = '\n\n'.join(complete_book_content)
                new_words = len(new_content.split())
                new_pages = new_words // 350
                words_added = new_words - current_words
                
                emit_generation_log(book_id, 'success', 
                    f'‚úÖ Chunk adicional √∫nico completado - +{words_added} palabras | Total: {new_pages}/{target_pages} p√°ginas')
            else:
                emit_generation_log(book_id, 'info', 
                    f'üöÄ OPTIMIZACI√ìN: Bucle while eliminado - Sin chunks adicionales necesarios')
            
            # Combinar todo el contenido
            final_content = '\n\n'.join(complete_book_content)
            final_thinking = '\n\n---CHUNK SEPARATOR---\n\n'.join(complete_thinking_content)
            
            # Calcular m√©tricas finales
            final_words = len(final_content.split())
            final_pages = final_words // 350  # ~350 words per page
            final_chapters = final_content.count('##')  # Contar headers de cap√≠tulos
            
            # Validar cumplimiento de p√°ginas prometidas
            requested_pages = approved_architecture.get('target_pages', book_params.get('page_count', 50))
            pages_ratio = final_pages / requested_pages if requested_pages > 0 else 1
            
            if pages_ratio < 0.95:  # Si faltan m√°s del 5%
                deficit_percentage = ((requested_pages - final_pages) / requested_pages) * 100
                logger.warning("multichunk_book_below_target",
                             book_id=book_id,
                             requested_pages=requested_pages,
                             actual_pages=final_pages,
                             deficit_percentage=deficit_percentage,
                             chunks_generated=chunk_num)
                
                emit_generation_log(book_id, 'warning', 
                    f'‚ö†Ô∏è Se generaron {final_pages} p√°ginas de las {requested_pages} solicitadas ({deficit_percentage:.1f}% menos)')
            else:
                emit_generation_log(book_id, 'success', 
                    f'‚úÖ Objetivo cumplido: {final_pages} p√°ginas generadas (solicitadas: {requested_pages})')
            
            # üìñ GENERAR CONCLUSI√ìN (si est√° configurada)
            emit_book_progress_update(book_id, {
                'current': 92,
                'total': 100,
                'status': 'generating_conclusion',
                'status_message': 'Generando conclusi√≥n personalizada del libro...',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            
            conclusion_result = await self._generate_conclusion(book_id, book_params, approved_architecture, final_content)
            if conclusion_result['content']:
                complete_book_content.append(conclusion_result['content'])
                complete_thinking_content.append(conclusion_result['thinking'])
                total_tokens_used += conclusion_result['usage']['total_tokens']
                total_thinking_tokens += conclusion_result['usage']['thinking_tokens']
                # Conclusion doesn't have separate prompt/completion tracking yet, but add placeholders
                total_prompt_tokens += conclusion_result['usage'].get('prompt_tokens', 0)
                total_completion_tokens += conclusion_result['usage'].get('completion_tokens', 0)
                
                # Recalcular contenido final con conclusi√≥n
                final_content = '\n\n'.join(complete_book_content)
                final_thinking = '\n\n---CHUNK SEPARATOR---\n\n'.join(complete_thinking_content)
                final_words = len(final_content.split())
                final_pages = final_words // 350
            
            # Progreso final
            emit_book_progress_update(book_id, {
                'current': 98,
                'total': 100,
                'status': 'finalizing',
                'status_message': f'Libro completado: {final_pages} p√°ginas, {final_words:,} palabras',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            
            # Debug thinking tokens in multichunk generation
            logger.info("multichunk_usage_debug", 
                       book_id=book_id,
                       total_tokens_used=total_tokens_used,
                       total_thinking_tokens=total_thinking_tokens,
                       total_prompt_tokens=total_prompt_tokens,
                       total_completion_tokens=total_completion_tokens,
                       token_sum_check=total_prompt_tokens + total_completion_tokens)
            
            # Resultado final
            return {
                'content': final_content,
                'thinking': final_thinking,
                'usage': {
                    'prompt_tokens': total_prompt_tokens,
                    'completion_tokens': total_completion_tokens,
                    'thinking_tokens': total_thinking_tokens,
                    'total_tokens': total_tokens_used
                },
                'model': self.model,
                'chunks_generated': chunk_num,  # Usar chunk_num real, no len(chunks) planeado
                'chunk_summaries': chunk_summaries,
                'final_stats': {
                    'pages': final_pages,
                    'words': final_words,
                    'chapters': final_chapters,
                    'pages_ratio': pages_ratio,
                    'target_pages': requested_pages
                }
            }
            
        except Exception as e:
            logger.error("multichunk_generation_error", 
                        book_id=book_id, 
                        error=str(e),
                        model=self.model)
            raise
    
    async def _generate_single_chunk(self, book_id: int, chunk_info: Dict, book_params: Dict[str, Any], 
                                   approved_architecture: Dict[str, Any], previous_content: str, 
                                   chunk_summaries: List[Dict], progress_base: int) -> Dict[str, Any]:
        """
        Genera un √∫nico chunk del libro con continuidad del anterior.
        """
        try:
            # Preparar prompt espec√≠fico para este chunk
            messages = self._build_chunk_messages(
                chunk_info, book_params, approved_architecture, 
                previous_content, chunk_summaries
            )
            
            # Variables de acumulaci√≥n para este chunk
            chunk_content = []
            chunk_thinking = []
            chunk_tokens = 0
            thinking_tokens = 0
            current_block_index = None
            
            from app.routes.websocket import emit_book_progress_update, emit_generation_log
            
            emit_book_progress_update(book_id, {
                'current': progress_base + 5,
                'total': 100,
                'status': 'thinking',
                'status_message': f'Claude Sonnet 4 analizando chunk {chunk_info["index"]}...',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            
            # üöÄ OPTIMIZACI√ìN: Generar con tokens optimizados para chunks principales
            chunk_max_tokens = self._get_optimized_tokens('chunk_main')  # 28000 optimizado
            chunk_thinking_budget = self._get_optimized_thinking_budget('chunk_main')  # Optimizado
            
            async with self.client.messages.stream(
                model=self.model,
                max_tokens=chunk_max_tokens,
                temperature=self.temperature,
                messages=messages,
                thinking={
                    "type": "enabled",
                    "budget_tokens": chunk_thinking_budget
                }
            ) as stream:
                
                async for event in stream:
                    # Thinking blocks
                    if event.type == "content_block_start" and event.content_block.type == "thinking":
                        current_block_index = event.index
                        emit_book_progress_update(book_id, {
                            'current': progress_base + 10,
                            'total': 100,
                            'status': 'deep_thinking',
                            'status_message': f'An√°lisis profundo chunk {chunk_info["index"]} - Pensamiento extendido activo...',
                            'timestamp': datetime.now(timezone.utc).isoformat()
                        })
                    
                    elif event.type == "content_block_delta" and hasattr(event, 'delta'):
                        # NUEVO: Thinking content via thinking_delta (multichunk)
                        if hasattr(event.delta, 'type') and event.delta.type == "thinking_delta":
                            if hasattr(event.delta, 'thinking'):
                                chunk_thinking.append(event.delta.thinking)
                                # Nota: thinking tokens se reportar√°n correctamente al final via usage
                        # Texto normal via text_delta
                        elif hasattr(event.delta, 'text'):
                            text_chunk = event.delta.text
                            # Content principal
                            chunk_content.append(text_chunk)
                            chunk_tokens += len(text_chunk.split())  # Estimaci√≥n temporal
                            
                            # Update progress
                            if len(chunk_content) % 50 == 0:
                                current_words = len(''.join(chunk_content).split())
                                emit_book_progress_update(book_id, {
                                    'current': progress_base + 15 + min(50, (len(chunk_content) // 10)),
                                    'total': 100,
                                    'status': 'writing',
                                    'status_message': f'Escribiendo chunk {chunk_info["index"]} - {current_words} palabras...',
                                    'timestamp': datetime.now(timezone.utc).isoformat()
                                })
                    
                    elif event.type == "content_block_stop":
                        if current_block_index == event.index:
                            # Fin del thinking
                            current_block_index = None
                            full_thinking = ''.join(chunk_thinking)
                            emit_generation_log(book_id, 'thinking', 
                                f'Chunk {chunk_info["index"]} - Planificaci√≥n: {len(full_thinking.split())} palabras de pensamiento')
                
                # Combinar contenido antes de usar
                final_chunk_content = ''.join(chunk_content)
                final_chunk_thinking = ''.join(chunk_thinking)
                
                # Obtener m√©tricas finales del stream
                final_message = await stream.get_final_message()
                prompt_tokens = 0
                completion_tokens = 0
                if hasattr(final_message, 'usage'):
                    prompt_tokens = final_message.usage.input_tokens
                    completion_tokens = final_message.usage.output_tokens
                    chunk_tokens = prompt_tokens + completion_tokens
                    thinking_tokens = getattr(final_message.usage, 'thinking_tokens', 0)
                    # Usar estimaci√≥n si API no reporta thinking tokens
                    if thinking_tokens == 0 and final_chunk_thinking:
                        thinking_tokens = self.estimate_thinking_tokens(final_chunk_thinking)
            
            emit_generation_log(book_id, 'success', 
                f'Chunk {chunk_info["index"]} generado: {len(final_chunk_content.split())} palabras, {thinking_tokens} thinking tokens')
            
            return {
                'content': final_chunk_content,
                'thinking': final_chunk_thinking,
                'usage': {
                    'prompt_tokens': prompt_tokens,
                    'completion_tokens': completion_tokens,
                    'thinking_tokens': thinking_tokens,
                    'total_tokens': chunk_tokens,
                    'chunk_info': chunk_info
                }
            }
            
        except Exception as e:
            logger.error("chunk_generation_error", 
                        book_id=book_id, 
                        chunk_index=chunk_info.get('index', 'unknown'),
                        error=str(e))
            raise
    
    async def _generate_introduction(self, book_id: int, book_params: Dict[str, Any], 
                                   approved_architecture: Dict[str, Any]) -> Dict[str, Any]:
        """
        Genera la introducci√≥n espec√≠fica del libro basada en la arquitectura aprobada.
        """
        try:
            introduction_info = approved_architecture.get('structure', {}).get('introduction', {})
            
            if not introduction_info or not book_params.get('include_introduction', True):
                return {'content': '', 'thinking': '', 'usage': {'total_tokens': 0}}
            
            language_map = {'es': 'Spanish', 'en': 'English', 'pt': 'Portuguese', 'fr': 'French'}
            language_name = language_map.get(book_params.get('language', 'es'), 'Spanish')
            
            # Calcular palabras precisas para introducci√≥n
            page_size = book_params.get('page_size', approved_architecture.get('page_size', 'pocket'))
            line_spacing = book_params.get('line_spacing', approved_architecture.get('line_spacing', 'medium'))
            words_per_page_matrix = {
                ('pocket', 'single'): 300, ('pocket', 'medium'): 240, ('pocket', 'double'): 180,
                ('A5', 'single'): 400, ('A5', 'medium'): 320, ('A5', 'double'): 240,
                ('B5', 'single'): 500, ('B5', 'medium'): 400, ('B5', 'double'): 300,
                ('letter', 'single'): 600, ('letter', 'medium'): 480, ('letter', 'double'): 360,
            }
            words_per_page = words_per_page_matrix.get((page_size, line_spacing), 240)
            intro_pages = introduction_info.get('pages', introduction_info.get('estimated_pages', 3))
            intro_words = intro_pages * words_per_page
            
            prompt = f"""
**GENERACI√ìN DE INTRODUCCI√ìN PROFESIONAL**

Escribe la introducci√≥n completa para este libro siguiendo exactamente la arquitectura aprobada.

**üìö INFORMACI√ìN DEL LIBRO:**
- T√≠tulo: {book_params.get('title', approved_architecture.get('title', 'Sin t√≠tulo'))}
- Descripci√≥n: {approved_architecture.get('summary', 'Descripci√≥n del libro')}
- G√©nero: {book_params.get('genre', approved_architecture.get('genre', 'General'))}
- Audiencia: {book_params.get('target_audience', approved_architecture.get('target_audience', 'General'))}
- Tono: {book_params.get('tone', approved_architecture.get('tone', 'Profesional'))}
- Estilo: {book_params.get('writing_style', approved_architecture.get('writing_style', 'Professional and engaging'))}

**üìù INTRODUCCI√ìN A GENERAR:**
- T√≠tulo: {introduction_info.get('title', 'Introducci√≥n')}
- Resumen: {introduction_info.get('summary', 'Introducci√≥n al tema del libro')}
- P√°ginas target: {intro_pages}
- Palabras target: {intro_words:,} (formato {page_size}/{line_spacing})

**üéØ INSTRUCCIONES ESPEC√çFICAS:**
1. Escribe en {language_name.upper()} exclusivamente
2. Mant√©n el tono {book_params.get('tone', 'profesional').upper()} y estilo "{book_params.get('writing_style', 'Professional and engaging')}"
3. Adapta para audiencia {book_params.get('target_audience', 'general')}
4. Genera exactamente {intro_words:,} palabras de contenido valioso
5. Incluye: presentaci√≥n del tema, importancia, qu√© aprender√° el lector, estructura del libro
6. Conecta directamente con el primer cap√≠tulo

üö® **OBLIGATORIEDAD CR√çTICA - TARGETING DE INTRODUCCI√ìN:**
- **P√ÅGINAS PROMETIDAS**: Esta introducci√≥n DEBE ocupar exactamente {intro_pages} p√°ginas
- **PALABRAS EXACTAS**: Target obligatorio = {intro_words:,} palabras (formato {page_size}/{line_spacing})
- **RESPONSABILIDAD**: Fallar el targeting = Comprometer p√°ginas totales del libro
- **EXPANSI√ìN OBLIGATORIA**: Si el contenido natural no alcanza {intro_words:,} palabras, expandir org√°nicamente
- **CALIDAD + CANTIDAD**: Mantener excelencia pero cumplir target de palabras sin excusas

Genera la introducci√≥n completa ahora:
"""

            messages = [{"role": "user", "content": [{"type": "text", "text": prompt}]}]
            
            intro_content = []
            intro_thinking = []
            current_block_index = None
            
            from app.routes.websocket import emit_generation_log
            emit_generation_log(book_id, 'info', 'Generando introducci√≥n personalizada...')
            
            async with self.client.messages.stream(
                model=self.model,
                max_tokens=self._get_optimized_tokens('introduction'),  # üöÄ 6000 optimizado para introducci√≥n
                temperature=self.temperature,
                messages=messages,
                thinking={"type": "enabled", "budget_tokens": min(12000, self.thinking_budget // 3)}  # üß† Ampliado thinking para introducci√≥n
            ) as stream:
                
                async for event in stream:
                    if event.type == "content_block_start" and event.content_block.type == "thinking":
                        current_block_index = event.index
                    elif event.type == "content_block_delta" and hasattr(event, 'delta'):
                        # NUEVO: Thinking content via thinking_delta (introducci√≥n)
                        if hasattr(event.delta, 'type') and event.delta.type == "thinking_delta":
                            if hasattr(event.delta, 'thinking'):
                                intro_thinking.append(event.delta.thinking)
                        # Texto normal via text_delta
                        elif hasattr(event.delta, 'text'):
                            text_chunk = event.delta.text
                            # Solo contenido no-thinking
                            if current_block_index is None or event.index != current_block_index:
                                intro_content.append(text_chunk)
                            else:
                                intro_content.append(text_chunk)
                    elif event.type == "content_block_stop":
                        if current_block_index == event.index:
                            current_block_index = None
                
                final_message = await stream.get_final_message()
            
            final_intro_content = ''.join(intro_content)
            final_intro_thinking = ''.join(intro_thinking)
            
            emit_generation_log(book_id, 'success', f'Introducci√≥n generada: {len(final_intro_content.split())} palabras')
            
            # Calcular thinking tokens con estimaci√≥n si es necesario
            thinking_tokens = getattr(final_message.usage, 'thinking_tokens', 0) if hasattr(final_message, 'usage') else 0
            if thinking_tokens == 0 and final_intro_thinking:
                thinking_tokens = self.estimate_thinking_tokens(final_intro_thinking)
            
            return {
                'content': final_intro_content,
                'thinking': final_intro_thinking,
                'usage': {
                    'total_tokens': final_message.usage.input_tokens + final_message.usage.output_tokens if hasattr(final_message, 'usage') else 0,
                    'thinking_tokens': thinking_tokens
                }
            }
            
        except Exception as e:
            logger.error("introduction_generation_error", book_id=book_id, error=str(e))
            return {'content': '', 'thinking': '', 'usage': {'total_tokens': 0}}
    
    async def _generate_conclusion(self, book_id: int, book_params: Dict[str, Any], 
                                 approved_architecture: Dict[str, Any], complete_content: str) -> Dict[str, Any]:
        """
        Genera la conclusi√≥n espec√≠fica del libro basada en la arquitectura aprobada y el contenido generado.
        """
        try:
            conclusion_info = approved_architecture.get('structure', {}).get('conclusion', {})
            
            if not conclusion_info or not book_params.get('include_conclusion', True):
                return {'content': '', 'thinking': '', 'usage': {'total_tokens': 0}}
            
            language_map = {'es': 'Spanish', 'en': 'English', 'pt': 'Portuguese', 'fr': 'French'}
            language_name = language_map.get(book_params.get('language', 'es'), 'Spanish')
            
            # Calcular palabras precisas para conclusi√≥n
            page_size = book_params.get('page_size', approved_architecture.get('page_size', 'pocket'))
            line_spacing = book_params.get('line_spacing', approved_architecture.get('line_spacing', 'medium'))
            words_per_page_matrix = {
                ('pocket', 'single'): 300, ('pocket', 'medium'): 240, ('pocket', 'double'): 180,
                ('A5', 'single'): 400, ('A5', 'medium'): 320, ('A5', 'double'): 240,
                ('B5', 'single'): 500, ('B5', 'medium'): 400, ('B5', 'double'): 300,
                ('letter', 'single'): 600, ('letter', 'medium'): 480, ('letter', 'double'): 360,
            }
            words_per_page = words_per_page_matrix.get((page_size, line_spacing), 240)
            conclusion_pages = conclusion_info.get('pages', conclusion_info.get('estimated_pages', 3))
            conclusion_words = conclusion_pages * words_per_page
            
            # Usar √∫ltimos 2000 caracteres del contenido para contexto
            content_context = complete_content[-2000:] if complete_content else ""
            
            prompt = f"""
**GENERACI√ìN DE CONCLUSI√ìN PROFESIONAL**

Escribe la conclusi√≥n completa para este libro siguiendo exactamente la arquitectura aprobada y sintetizando el contenido generado.

**üìö INFORMACI√ìN DEL LIBRO:**
- T√≠tulo: {book_params.get('title', approved_architecture.get('title', 'Sin t√≠tulo'))}
- Descripci√≥n: {approved_architecture.get('summary', 'Descripci√≥n del libro')}
- G√©nero: {book_params.get('genre', approved_architecture.get('genre', 'General'))}
- Audiencia: {book_params.get('target_audience', approved_architecture.get('target_audience', 'General'))}
- Tono: {book_params.get('tone', approved_architecture.get('tone', 'Profesional'))}
- Estilo: {book_params.get('writing_style', approved_architecture.get('writing_style', 'Professional and engaging'))}

**üìù CONCLUSI√ìN A GENERAR:**
- T√≠tulo: {conclusion_info.get('title', 'Conclusi√≥n')}
- Resumen: {conclusion_info.get('summary', 'Resumen y reflexiones finales')}
- P√°ginas target: {conclusion_pages}
- Palabras target: {conclusion_words:,} (formato {page_size}/{line_spacing})

**üìñ CONTEXTO DEL CONTENIDO FINAL:**
```
{content_context}
```

**üéØ INSTRUCCIONES ESPEC√çFICAS:**
1. Escribe en {language_name.upper()} exclusivamente
2. Mant√©n el tono {book_params.get('tone', 'profesional').upper()} y estilo "{book_params.get('writing_style', 'Professional and engaging')}"
3. Adapta para audiencia {book_params.get('target_audience', 'general')}
4. Genera exactamente {conclusion_words:,} palabras de contenido valioso
5. Sintetiza los puntos clave del libro completo
6. Incluye: resumen de aprendizajes, reflexiones finales, pr√≥ximos pasos
7. Cierra de manera inspiradora y coherente con todo el contenido

üö® **OBLIGATORIEDAD CR√çTICA - TARGETING DE CONCLUSI√ìN:**
- **P√ÅGINAS PROMETIDAS**: Esta conclusi√≥n DEBE ocupar exactamente {conclusion_pages} p√°ginas
- **PALABRAS EXACTAS**: Target obligatorio = {conclusion_words:,} palabras (formato {page_size}/{line_spacing})
- **RESPONSABILIDAD**: Fallar el targeting = Comprometer p√°ginas totales prometidas al cliente
- **EXPANSI√ìN OBLIGATORIA**: Si el contenido natural no alcanza {conclusion_words:,} palabras, expandir org√°nicamente
- **CALIDAD + CANTIDAD**: Mantener excelencia pero cumplir target de palabras sin excusas
- **CIERRE COMPLETO**: Una conclusi√≥n corta = Libro incompleto = Cliente insatisfecho

Genera la conclusi√≥n completa ahora:
"""

            messages = [{"role": "user", "content": [{"type": "text", "text": prompt}]}]
            
            conclusion_content = []
            conclusion_thinking = []
            current_block_index = None
            
            from app.routes.websocket import emit_generation_log
            emit_generation_log(book_id, 'info', 'Generando conclusi√≥n personalizada...')
            
            async with self.client.messages.stream(
                model=self.model,
                max_tokens=self._get_optimized_tokens('conclusion'),  # üöÄ 6000 optimizado para conclusi√≥n
                temperature=self.temperature,
                messages=messages,
                thinking={"type": "enabled", "budget_tokens": min(12000, self.thinking_budget // 3)}  # üß† Ampliado thinking para conclusi√≥n
            ) as stream:
                
                async for event in stream:
                    if event.type == "content_block_start" and event.content_block.type == "thinking":
                        current_block_index = event.index
                    elif event.type == "content_block_delta" and hasattr(event, 'delta'):
                        # NUEVO: Thinking content via thinking_delta (conclusi√≥n)
                        if hasattr(event.delta, 'type') and event.delta.type == "thinking_delta":
                            if hasattr(event.delta, 'thinking'):
                                conclusion_thinking.append(event.delta.thinking)
                        # Texto normal via text_delta
                        elif hasattr(event.delta, 'text'):
                            text_chunk = event.delta.text
                            # Solo contenido no-thinking
                            if current_block_index is None or event.index != current_block_index:
                                conclusion_content.append(text_chunk)
                    elif event.type == "content_block_stop":
                        if current_block_index == event.index:
                            current_block_index = None
                
                final_message = await stream.get_final_message()
            
            final_conclusion_content = ''.join(conclusion_content)
            final_conclusion_thinking = ''.join(conclusion_thinking)
            
            emit_generation_log(book_id, 'success', f'Conclusi√≥n generada: {len(final_conclusion_content.split())} palabras')
            
            # Calcular thinking tokens con estimaci√≥n si es necesario
            thinking_tokens = getattr(final_message.usage, 'thinking_tokens', 0) if hasattr(final_message, 'usage') else 0
            if thinking_tokens == 0 and final_conclusion_thinking:
                thinking_tokens = self.estimate_thinking_tokens(final_conclusion_thinking)
            
            return {
                'content': final_conclusion_content,
                'thinking': final_conclusion_thinking,
                'usage': {
                    'total_tokens': final_message.usage.input_tokens + final_message.usage.output_tokens if hasattr(final_message, 'usage') else 0,
                    'thinking_tokens': thinking_tokens
                }
            }
            
        except Exception as e:
            logger.error("conclusion_generation_error", book_id=book_id, error=str(e))
            return {'content': '', 'thinking': '', 'usage': {'total_tokens': 0}}
    
    def _build_chunk_messages(self, chunk_info: Dict, book_params: Dict[str, Any], 
                            approved_architecture: Dict[str, Any], previous_content: str, 
                            chunk_summaries: List[Dict]) -> List[Dict[str, Any]]:
        """
        Construye los mensajes para generar un chunk espec√≠fico manteniendo continuidad.
        """
        language_map = {
            'es': 'Spanish',
            'en': 'English', 
            'pt': 'Portuguese',
            'fr': 'French'
        }
        
        user_language = book_params.get('language', 'es')
        language_name = language_map.get(user_language, user_language)
        
        # Construir contexto de continuidad
        continuity_context = ""
        if previous_content:
            # √öltimos 1000 caracteres para continuidad
            continuity_context = f"""
**CONTENIDO PREVIO (para continuidad):**
```
{previous_content[-1000:]}
```

**RES√öMENES DE CHUNKS ANTERIORES:**
{chr(10).join([f"Chunk {s['chunk_number']} (Cap {s['chapters']}): {s['word_count']} palabras - {s['summary'][:200]}..." for s in chunk_summaries])}
"""
        
        # Cap√≠tulos a generar en este chunk
        chapters_to_generate = ""
        
        # üö® MANEJO INTELIGENTE DE CHUNKS DE CONTINUACI√ìN
        if chunk_info.get('is_continuation', False):
            continuation_strategy = chunk_info.get('continuation_strategy', {})
            strategy_type = continuation_strategy.get('type', 'expand_existing')
            target_pages_remaining = chunk_info.get('target_pages_remaining', 50)
            target_words_remaining = chunk_info.get('target_words_remaining', 17500)
            generated_chapters = chunk_info.get('generated_chapters', [])
            
            if strategy_type == 'expand_existing':
                strategy_prompt = f"""
**üîÑ EXPANSI√ìN DE CONTENIDO EXISTENTE**
- Expandir cap√≠tulos ya generados con contenido adicional detallado
- Agregar subsecciones, ejemplos pr√°cticos m√°s profundos, casos de estudio
- Incluir ejercicios adicionales, FAQ, troubleshooting
- NO crear nuevos cap√≠tulos, solo EXPANDIR los existentes
"""
            elif strategy_type == 'add_sections':
                strategy_prompt = f"""
**üîÑ AGREGAR SECCIONES ESPECIALES**
- Crear secciones complementarias: Ap√©ndices, Glosario, Recursos adicionales
- Casos de estudio reales detallados, proyectos pr√°cticos completos
- Secci√≥n de mejores pr√°cticas, patrones comunes, anti-patrones
- Referencias bibliogr√°ficas expandidas, lecturas recomendadas
"""
            else:  # add_chapters
                strategy_prompt = f"""
**üîÑ AGREGAR CAP√çTULOS ADICIONALES**
- Crear nuevos cap√≠tulos que complementen los existentes
- Temas avanzados, casos de uso especializados
- Cap√≠tulos de implementaci√≥n pr√°ctica, proyectos completos
- Conclusiones expandidas, roadmap futuro, recursos adicionales
"""
            
            chapters_to_generate = f"""
{strategy_prompt}

**CONTEXTO DE CONTINUACI√ìN:**
- P√°ginas restantes necesarias: {target_pages_remaining}
- Palabras aproximadas a generar: {target_words_remaining:,}
- Cap√≠tulos ya generados: {', '.join(generated_chapters[:5])}{'...' if len(generated_chapters) > 5 else ''}
- CR√çTICO: NO repetir contenido ya generado
- ENFOQUE: {continuation_strategy.get('strategy', 'Expandir contenido existente')}
"""
        else:
            # Chunk normal con cap√≠tulos espec√≠ficos de la arquitectura
            total_chunk_pages = chunk_info.get('target_pages', 0)
            
            chapters_to_generate += f"""
**üìã CHUNK PLANIFICADO - {total_chunk_pages} P√ÅGINAS TARGET**

"""
            # Calcular palabras precisas por p√°gina basado en formato
            page_size = book_params.get('page_size', approved_architecture.get('page_size', 'pocket'))
            line_spacing = book_params.get('line_spacing', approved_architecture.get('line_spacing', 'medium'))
            
            # Palabras por p√°gina espec√≠ficas por formato (m√°s precisas)
            words_per_page_matrix = {
                ('pocket', 'single'): 300, ('pocket', 'medium'): 240, ('pocket', 'double'): 180,
                ('A5', 'single'): 400, ('A5', 'medium'): 320, ('A5', 'double'): 240,
                ('B5', 'single'): 500, ('B5', 'medium'): 400, ('B5', 'double'): 300,
                ('letter', 'single'): 600, ('letter', 'medium'): 480, ('letter', 'double'): 360,
            }
            words_per_page = words_per_page_matrix.get((page_size, line_spacing), 240)
            
            for i, chapter in enumerate(chunk_info['chapters']):
                chapter_pages = chapter.get('estimated_pages', chapter.get('pages', 0))
                chapter_words = chapter_pages * words_per_page
                chapters_to_generate += f"""
**CAP√çTULO {chapter.get('number', chapter.get('chapter_number', chunk_info['start_chapter'] + i))}: {chapter.get('title', f'Cap√≠tulo {chunk_info["start_chapter"] + i}')}**
- Resumen: {chapter.get('summary', 'Contenido del cap√≠tulo')}
- Puntos clave: {', '.join(chapter.get('key_points', []))}
- Objetivos de aprendizaje: {', '.join(chapter.get('learning_objectives', []))}
- üö® **P√ÅGINAS OBLIGATORIAS**: {chapter_pages} p√°ginas EXACTAS (NO negociable)
- üö® **PALABRAS TARGET**: {chapter_words:,} palabras m√≠nimas (formato {page_size}/{line_spacing})
"""
        
        # Tipo de chunk para instrucciones espec√≠ficas
        chunk_type = "DE CONTINUACI√ìN" if chunk_info.get('is_continuation', False) else "PLANIFICADO"
        
        # Formatear target_words correctamente
        target_words = chunk_info.get('target_words', 'NO ESPECIFICADO')
        if isinstance(target_words, (int, float)):
            target_words_str = f"{int(target_words):,}"
        else:
            target_words_str = str(target_words)
        
        user_prompt = f"""
**CLAUDE SONNET 4 - GENERACI√ìN MULTI-CHUNKED DE ALTA CALIDAD**

Est√°s generando el CHUNK {chunk_type} {chunk_info['index']} de un libro. Debes mantener PERFECTA CONTINUIDAD y M√ÅXIMA CALIDAD.

{continuity_context}

**üìö INFORMACI√ìN COMPLETA DEL LIBRO:**
- T√≠tulo: {book_params.get('title', approved_architecture.get('title', 'Sin t√≠tulo'))}
- Descripci√≥n general: {approved_architecture.get('summary', 'Descripci√≥n del libro')}
- G√©nero: {book_params.get('genre', approved_architecture.get('genre', 'General'))}
- Idioma: {language_name.upper()}
- Audiencia objetivo: {book_params.get('target_audience', approved_architecture.get('target_audience', 'General'))}
- Tono requerido: {book_params.get('tone', approved_architecture.get('tone', 'Profesional'))}
- Estilo de escritura: {book_params.get('writing_style', approved_architecture.get('writing_style', 'Professional and engaging'))}

**üìñ ESTRUCTURA COMPLETA DEL LIBRO (para evitar duplicaci√≥n):**
{self._build_complete_book_structure(approved_architecture)}

**üìñ ESPECIFICACIONES DE FORMATO:**
- Formato de p√°gina: {book_params.get('page_size', approved_architecture.get('page_size', 'pocket'))}
- Interlineado: {book_params.get('line_spacing', approved_architecture.get('line_spacing', 'medium'))}
- Target p√°ginas total: {approved_architecture.get('target_pages', 'No especificado')}
- Target palabras total: {approved_architecture.get('estimated_words', 'No especificado'):,}
- Include TOC: {book_params.get('include_toc', approved_architecture.get('include_toc', True))}
- Include Introduction: {book_params.get('include_introduction', approved_architecture.get('include_introduction', True))}
- Include Conclusion: {book_params.get('include_conclusion', approved_architecture.get('include_conclusion', True))}

**üìù CONTENIDO A GENERAR:**
{chapters_to_generate}

**üéØ INSTRUCCIONES CR√çTICAS DE CALIDAD:**
1. **IDIOMA**: Escribe en {language_name.upper()} exclusivamente
2. **G√âNERO**: Adapta el contenido espec√≠ficamente al g√©nero {book_params.get('genre', approved_architecture.get('genre', 'General')).upper()} - usa t√©cnicas, estructura y enfoque apropiados
3. **ESTILO DE ESCRITURA**: Sigue estrictamente el estilo "{book_params.get('writing_style', approved_architecture.get('writing_style', 'Professional and engaging'))}" en cada p√°rrafo
4. **TONO**: Mant√©n consistentemente el tono {book_params.get('tone', approved_architecture.get('tone', 'Profesional')).upper()} durante todo el contenido
5. **AUDIENCIA**: Escribe espec√≠ficamente para {book_params.get('target_audience', approved_architecture.get('target_audience', 'General'))} - adapta vocabulario y ejemplos
6. **CONTENIDO**: Genera contenido COMPLETO, EXTENSO y VALIOSO (no res√∫menes ni relleno)
7. **CONTINUIDAD**: Mant√©n perfecci√≥n narrativa con contenido anterior - sin cortes abruptos
8. **ESTRUCTURA**: {"Contin√∫a expandiendo org√°nicamente donde qued√≥" if chunk_info.get('is_continuation', False) else "Empieza directamente con el primer cap√≠tulo de este chunk"}
9. **PROFUNDIDAD**: Cada concepto debe desarrollarse con m√∫ltiples niveles de profundidad
10. **EJEMPLOS**: Incluye casos reales, an√©cdotas, met√°foras que ilustren cada punto espec√≠ficos del contexto descrito
11. **VALOR PR√ÅCTICO**: Proporciona consejos implementables, herramientas y metodolog√≠as relevantes al tema
12. **ENGAGEMENT**: Mant√©n al lector enganchado con contenido interesante y relevante al g√©nero y audiencia
13. **üö® NO DUPLICACI√ìN**: NUNCA repitas informaci√≥n que ya aparece en otros cap√≠tulos de la estructura completa mostrada arriba. Cada cap√≠tulo debe tener contenido √∫nico y espec√≠fico

**üìö T√âCNICAS DE EXPANSI√ìN NATURAL:**
- **Contexto hist√≥rico**: C√≥mo evolucionaron los conceptos, antecedentes relevantes
- **M√∫ltiples perspectivas**: Diferentes escuelas de pensamiento, enfoques alternativos  
- **Casos de estudio detallados**: Ejemplos reales con an√°lisis profundo
- **Implementaci√≥n pr√°ctica**: Pasos espec√≠ficos, frameworks, metodolog√≠as
- **Problemas y soluciones**: Challenges comunes y c√≥mo resolverlos
- **Herramientas y recursos**: Software, t√©cnicas, recursos √∫tiles
- **Conexiones interdisciplinarias**: C√≥mo se relaciona con otros campos
- **Ejercicios reflexivos**: Preguntas que inviten al an√°lisis del lector

**üö® CALIDAD SOBRE CANTIDAD**: El objetivo es generar contenido naturalmente extenso de ALTO VALOR, no relleno. Cada p√°rrafo debe aportar valor √∫nico al lector.

üö® **OBLIGATORIEDAD CR√çTICA - CUMPLIMIENTO DE P√ÅGINAS:**
- **PROMESA COMERCIAL**: Este chunk DEBE generar exactamente las p√°ginas asignadas en la arquitectura
- **TARGETING OBLIGATORIO**: Target p√°ginas = {chunk_info.get('target_pages', 'NO ESPECIFICADO')} p√°ginas
- **TARGET PALABRAS**: {target_words_str} palabras (formato {book_params.get('page_size', 'pocket')}/{book_params.get('line_spacing', 'medium')})
- **RESPONSABILIDAD TOTAL**: Generar menos = Fallar la promesa al cliente pagador
- **P√ÅGINAS POR CAP√çTULO**: CADA cap√≠tulo individual debe cumplir sus p√°ginas estimadas de la arquitectura
- **NO DISTRIBUCI√ìN DESIGUAL**: No generar cap√≠tulos cortos para compensar con otros largos
- **EXPANSI√ìN OBLIGATORIA**: Si el contenido natural no alcanza el target, DEBES expandir org√°nicamente
- **NO SUBESTIMAR**: Es mejor generar 110% del target que 90%
- **VERIFICACI√ìN**: Cada p√°rrafo cuenta hacia el cumplimiento de p√°ginas prometidas

{"üîÑ CONTINUACI√ìN: Expande org√°nicamente el contenido para alcanzar las p√°ginas faltantes manteniendo la excelencia" if chunk_info.get('is_continuation', False) else "‚úçÔ∏è CREACI√ìN: Desarrolla cada cap√≠tulo con la profundidad que merece seg√∫n la arquitectura aprobada"}"""

        return [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": user_prompt
                    }
                ]
            }
        ]
    
    def _build_complete_book_structure(self, approved_architecture: Dict[str, Any]) -> str:
        """
        Construye una vista completa de la estructura del libro para evitar duplicaci√≥n entre chunks.
        """
        structure = approved_architecture.get('structure', {})
        chapters = structure.get('chapters', [])
        
        if not chapters:
            return "Estructura de cap√≠tulos no disponible"
        
        structure_text = "TODOS LOS CAP√çTULOS DEL LIBRO (NO duplicar contenido entre ellos):\n"
        
        # Incluir introducci√≥n si existe
        if structure.get('introduction'):
            intro = structure['introduction']
            structure_text += f"üìñ INTRODUCCI√ìN: {intro.get('title', 'Introducci√≥n')}\n"
            structure_text += f"   - Resumen: {intro.get('summary', 'Introducci√≥n al libro')}\n"
            structure_text += f"   - P√°ginas: {intro.get('pages', 'N/A')}\n\n"
        
        # Incluir todos los cap√≠tulos
        for i, chapter in enumerate(chapters, 1):
            chapter_title = chapter.get('title', f'Cap√≠tulo {i}')
            chapter_summary = chapter.get('summary', 'Sin resumen')
            chapter_pages = chapter.get('pages', chapter.get('estimated_pages', 'N/A'))
            key_points = chapter.get('key_points', [])
            
            structure_text += f"üìö CAP√çTULO {i}: {chapter_title}\n"
            structure_text += f"   - Resumen: {chapter_summary}\n"
            structure_text += f"   - P√°ginas: {chapter_pages}\n"
            if key_points:
                structure_text += f"   - Puntos clave: {', '.join(key_points[:3])}\n"
            structure_text += "\n"
        
        # Incluir conclusi√≥n si existe
        if structure.get('conclusion'):
            conclusion = structure['conclusion']
            structure_text += f"üìñ CONCLUSI√ìN: {conclusion.get('title', 'Conclusi√≥n')}\n"
            structure_text += f"   - Resumen: {conclusion.get('summary', 'Conclusi√≥n del libro')}\n"
            structure_text += f"   - P√°ginas: {conclusion.get('pages', 'N/A')}\n\n"
        
        structure_text += """üö® REGLAS DE NO DUPLICACI√ìN:
‚Ä¢ NO generes el contenido principal que ya pertenezca a otros cap√≠tulos listados arriba
‚Ä¢ S√ç puedes hacer referencias breves a temas de otros cap√≠tulos si complementan el objetivo del cap√≠tulo actual
‚Ä¢ S√ç puedes mencionar conceptos de otros cap√≠tulos para dar contexto o conectar ideas
‚Ä¢ NO desarrolles en profundidad temas que son el foco principal de otros cap√≠tulos
‚Ä¢ Mant√©n el enfoque en el prop√≥sito espec√≠fico del cap√≠tulo que est√°s generando"""
        
        return structure_text
    
    # =====================================
    # EXPANSI√ìN ORG√ÅNICA PARA CUMPLIMIENTO DE P√ÅGINAS
    # =====================================
    
    async def _expand_content_organically(self, content: str, target_words: int, book_params: Dict[str, Any], 
                                        approved_architecture: Dict[str, Any]) -> str:
        """Expande contenido de manera org√°nica manteniendo calidad y fluidez narrativa"""
        
        current_words = len(content.split())
        words_needed = target_words - current_words
        
        if words_needed <= 0:
            return content
        
        # Obtener informaci√≥n del libro para contexto
        language_map = {'es': 'Spanish', 'en': 'English', 'pt': 'Portuguese', 'fr': 'French'}
        language_name = language_map.get(book_params.get('language', 'es'), 'Spanish')
        
        expansion_prompt = f"""**EXPANSI√ìN ORG√ÅNICA DE CONTENIDO DE ALTA CALIDAD**

Eres un editor experto especializado en enriquecer libros manteniendo fluidez narrativa perfecta.

**CONTENIDO ACTUAL A EXPANDIR:**
```
{content}
```

**OBJETIVO DE EXPANSI√ìN:**
- Palabras actuales: {current_words:,}
- Palabras objetivo: {target_words:,}
- Palabras a agregar: {words_needed:,}
- Idioma: {language_name.upper()}

**INFORMACI√ìN DEL LIBRO (mantener coherencia):**
- T√≠tulo: {book_params.get('title', 'Sin t√≠tulo')}
- G√©nero: {book_params.get('genre', 'General')}
- Audiencia: {book_params.get('target_audience', 'General')}
- Tono: {book_params.get('tone', 'Profesional')}

**ESTRUCTURA COMPLETA DEL LIBRO (NO duplicar contenido de otros cap√≠tulos):**
{self._build_complete_book_structure(approved_architecture)}

**T√âCNICAS DE EXPANSI√ìN ORG√ÅNICA (NO usar todas, elegir las m√°s apropiadas):**

1. **PROFUNDIZACI√ìN CONCEPTUAL:**
   - Desarrolla m√°s las ideas principales con explicaciones adicionales
   - Agrega niveles de detalle que no estaban presentes
   - Incluye matices y sutilezas importantes

2. **CASOS PR√ÅCTICOS REALES:**
   - Ejemplos espec√≠ficos de la vida real o industria
   - Estudios de caso con an√°lisis detallado
   - Escenarios hipot√©ticos pero realistas

3. **IMPLEMENTACI√ìN DETALLADA:**
   - Pasos espec√≠ficos y metodolog√≠as
   - Herramientas y t√©cnicas concretas
   - Frameworks y procesos detallados

4. **CONTEXTO ENRIQUECEDOR:**
   - Antecedentes hist√≥ricos relevantes
   - Evoluci√≥n de conceptos o t√©cnicas
   - Perspectivas culturales o regionales

5. **M√öLTIPLES PERSPECTIVAS:**
   - Diferentes enfoques o escuelas de pensamiento
   - Pros y contras de distintas aproximaciones
   - Debates actuales en el campo

6. **VALOR PR√ÅCTICO ADICIONAL:**
   - Consejos implementables inmediatamente
   - Errores comunes y c√≥mo evitarlos
   - Mejores pr√°cticas y lecciones aprendidas

7. **CONEXIONES Y S√çNTESIS:**
   - Relaciones con otros conceptos del libro
   - Aplicaciones en diferentes contextos
   - S√≠ntesis de m√∫ltiples ideas

**RESTRICCIONES CR√çTICAS:**
‚ùå NO repetir informaci√≥n ya presente
‚ùå NO agregar relleno o contenido irrelevante  
‚ùå NO cambiar el tono o estilo existente
‚ùå NO romper la fluidez narrativa
‚ùå NO crear secciones desconectadas

‚úÖ MANTENER la estructura y organizaci√≥n actual
‚úÖ RESPETAR los t√≠tulos y subt√≠tulos existentes
‚úÖ PRESERVAR las transiciones naturales
‚úÖ ASEGURAR que cada adici√≥n sea valiosa

**RESULTADO ESPERADO:**
Contenido expandido que se lea como si siempre hubiera tenido esa extensi√≥n, rico en valor y perfectamente fluido. El lector no debe notar d√≥nde terminaba el contenido original y d√≥nde empez√≥ la expansi√≥n.

üö® **OBLIGATORIEDAD CR√çTICA - EXPANSI√ìN PARA CUMPLIR P√ÅGINAS:**
- **PROMESA COMERCIAL**: El usuario pag√≥ por {target_words:,} palabras y DEBEMOS entregarlas
- **D√âFICIT ACTUAL**: Faltan {words_needed:,} palabras para cumplir la promesa
- **RESPONSABILIDAD TOTAL**: No alcanzar el target = Fallar al cliente pagador
- **EXPANSI√ìN OBLIGATORIA**: DEBES agregar exactamente {words_needed:,} palabras (o m√°s)
- **CALIDAD MANTENIDA**: La expansi√≥n debe mantener la excelencia del contenido original
- **NO RELLENO**: Cada palabra agregada debe aportar valor real al lector
- **VERIFICACI√ìN**: El resultado final DEBE tener m√≠nimo {target_words:,} palabras

**INSTRUCCI√ìN FINAL:**
Devuelve el contenido completo expandido, manteniendo TODO el contenido original m√°s las adiciones org√°nicas. Escribe en {language_name.upper()} exclusivamente."""

        try:
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=32000,  # Suficiente para expansi√≥n
                temperature=0.7,   # Creatividad controlada
                messages=[{
                    "role": "user",
                    "content": expansion_prompt
                }]
            )
            
            expanded_content = ""
            for block in response.content:
                if hasattr(block, 'text'):
                    expanded_content += block.text
            
            logger.info("organic_expansion_completed",
                       original_words=current_words,
                       target_words=target_words,
                       final_words=len(expanded_content.split()),
                       expansion_success=len(expanded_content.split()) > current_words)
            
            return expanded_content.strip()
            
        except Exception as e:
            logger.error("organic_expansion_failed", error=str(e))
            return content  # Devolver contenido original si falla
    
    async def _validate_chunk_quality_and_length(self, chunk_content: str, target_pages: int, 
                                                book_id: int, chunk_info: Dict[str, Any]) -> Dict[str, Any]:
        """Validaci√≥n suave que prioriza calidad pero busca cumplir target de p√°ginas"""
        
        actual_words = len(chunk_content.split())
        actual_pages = actual_words // 350
        target_words = target_pages * 350
        
        compliance_ratio = actual_pages / target_pages if target_pages > 0 else 1
        
        # Validaci√≥n con rangos flexibles que priorizan calidad
        if compliance_ratio >= 0.90:  # 90% o m√°s es excelente
            status = "excellent" if compliance_ratio >= 0.95 else "very_good"
            return {
                'status': status,
                'actual_words': actual_words,
                'actual_pages': actual_pages,
                'target_pages': target_pages,
                'compliance_ratio': compliance_ratio,
                'meets_target': True,
                'needs_expansion': False,
                'quality_preserved': True,
                'message': f"‚úÖ Chunk {chunk_info.get('index', '?')}: {actual_pages}/{target_pages} p√°ginas ({compliance_ratio:.1%})"
            }
        
        elif compliance_ratio >= 0.75:  # 75-90% - expansi√≥n org√°nica recomendada
            return {
                'status': 'expandable',
                'actual_words': actual_words,
                'actual_pages': actual_pages,
                'target_pages': target_pages,
                'compliance_ratio': compliance_ratio,
                'meets_target': compliance_ratio >= 0.90,
                'needs_expansion': True,
                'expansion_words': target_words - actual_words,
                'quality_preserved': True,
                'message': f"üìà Chunk {chunk_info.get('index', '?')}: {actual_pages}/{target_pages} p√°ginas - Expansi√≥n org√°nica recomendada"
            }
        
        else:  # Menos de 75% - posible problema en la generaci√≥n
            logger.warning("chunk_significantly_under_target", 
                          book_id=book_id, 
                          chunk_index=chunk_info.get('index', '?'),
                          actual_pages=actual_pages, 
                          target_pages=target_pages)
            return {
                'status': 'concerning',
                'actual_words': actual_words,
                'actual_pages': actual_pages,
                'target_pages': target_pages,
                'compliance_ratio': compliance_ratio,
                'meets_target': False,
                'needs_expansion': True,
                'expansion_words': target_words - actual_words,
                'quality_preserved': True,
                'message': f"‚ö†Ô∏è Chunk {chunk_info.get('index', '?')}: {actual_pages}/{target_pages} p√°ginas - Revisi√≥n necesaria"
            }

    # =====================================
    # M√âTODOS DE SOPORTE PARA REGENERACI√ìN DE CAP√çTULOS
    # =====================================
    
    def _build_chapter_regeneration_messages(self, chapter_content: str, feedback: Dict[str, str], book=None) -> List[Dict[str, Any]]:
        """Construye los mensajes para la regeneraci√≥n de cap√≠tulos."""
        return [
            {
                "role": "system",
                "content": self._build_chapter_regeneration_system_prompt()
            },
            {
                "role": "user", 
                "content": self._build_chapter_regeneration_user_prompt(chapter_content, feedback, book)
            }
        ]
    
    async def _generate_chunk_parallel(self, book_id: int, chunk_info: Dict, book_params: Dict[str, Any], 
                                     approved_architecture: Dict[str, Any], introduction_content: str, 
                                     chunk_idx: int) -> Dict[str, Any]:
        """
        üöÄ Genera un chunk de forma independiente para ejecuci√≥n paralela.
        Optimizado para m√°xima velocidad sin sacrificar calidad.
        """
        from app.routes.websocket import emit_generation_log
        
        try:
            chunk_num = chunk_info['index']
            
            emit_generation_log(book_id, 'info', 
                f'üöÄ Chunk paralelo {chunk_num} iniciado: {len(chunk_info["chapters"])} cap√≠tulos')
            
            # Generar contenido usando el m√©todo existente pero sin contexto de chunks previos
            chunk_result = await self._generate_single_chunk(
                book_id=book_id,
                chunk_info=chunk_info,
                book_params=book_params,
                approved_architecture=approved_architecture,
                previous_content=introduction_content,  # Solo usar introducci√≥n como contexto
                chunk_summaries=[],  # Sin dependencias de chunks previos
                progress_base=30 + (chunk_idx * 30)  # Progreso distribuido
            )
            
            emit_generation_log(book_id, 'success', 
                f'‚úÖ Chunk paralelo {chunk_num} completado: {len(chunk_result["content"].split())} palabras')
            
            return chunk_result
            
        except Exception as e:
            emit_generation_log(book_id, 'error', 
                f'‚ùå Error en chunk paralelo {chunk_num}: {str(e)}')
            raise
    
    def _build_chapter_regeneration_system_prompt(self) -> str:
        """Prompt del sistema para regeneraci√≥n de cap√≠tulos."""
        return """Eres un escritor experto y editor profesional especializado en mejorar cap√≠tulos de libros bas√°ndote en feedback espec√≠fico de usuarios.

Tu tarea es regenerar completamente cap√≠tulos existentes, mejor√°ndolos seg√∫n las indicaciones del usuario, manteniendo siempre:
- Coherencia con el tema y prop√≥sito del libro
- Estructura profesional y bien organizada
- Contenido m√°s extenso y detallado que el original
- Ejemplos pr√°cticos y casos de estudio relevantes
- Formato Markdown apropiado y profesional
- Tono profesional pero accesible

Caracter√≠sticas espec√≠ficas de formato y estructura que DEBES seguir:

**üìù FORMATO MARKDOWN PROFESIONAL:**
- Utiliza encabezados H2 (##) para t√≠tulos principales
- Utiliza encabezados H3 (###) para subtemas y secciones
- Utiliza encabezados H4 (####) para subsecciones cuando sea necesario
- Incluye listas con vi√±etas (-) y numeradas (1.) seg√∫n corresponda
- Utiliza **texto en negrita** para t√©rminos clave e importantes
- Utiliza *cursiva* para √©nfasis y conceptos
- Incluye citas y bloques destacados usando > cuando sea apropiado
- Utiliza tablas en Markdown cuando ayuden a organizar informaci√≥n
- Incluye separadores (---) entre secciones principales cuando mejore la legibilidad

**üìä ESTRUCTURA Y ORGANIZACI√ìN:**
- Comienza cada cap√≠tulo con una breve introducci√≥n que contextualice el tema
- Organiza el contenido en secciones l√≥gicas y bien definidas
- Incluye ejemplos pr√°cticos, casos de estudio y an√©cdotas relevantes
- Termina cada cap√≠tulo con una conclusi√≥n o resumen de puntos clave
- Aseg√∫rate de que haya transiciones suaves entre secciones
- Mant√©n un flujo narrativo coherente y profesional

**üìè EXTENSI√ìN Y DETALLE:**
- Haz el contenido significativamente m√°s extenso que el original
- Desarrolla cada punto con profundidad y detalle
- Incluye m√∫ltiples ejemplos y casos pr√°cticos
- Agrega contexto hist√≥rico, estad√≠sticas o datos relevantes cuando sea apropiado
- Expande conceptos con explicaciones claras y accesibles

**‚úÖ INSTRUCCIONES FINALES:**
- Mant√©n el t√≠tulo del cap√≠tulo pero transforma completamente el contenido
- Responde EXCLUSIVAMENTE con el contenido del cap√≠tulo regenerado en Markdown
- NO incluyas metadatos, comentarios o explicaciones fuera del contenido del cap√≠tulo
- Aseg√∫rate de que el resultado sea un cap√≠tulo completo, profesional y bien estructurado"""
    
    def _build_chapter_regeneration_user_prompt(self, chapter_content: str, feedback: Dict[str, str], book=None) -> str:
        """Prompt del usuario para regeneraci√≥n de cap√≠tulos."""
        
        # Calcular palabras recomendadas basado en la arquitectura del libro +20%
        target_words = "extenso y detallado"
        if book and hasattr(book, 'architecture') and book.architecture:
            try:
                # Obtener palabras estimadas de la arquitectura
                estimated_words = book.architecture.get('estimated_words', 0)
                if estimated_words > 0:
                    # Obtener n√∫mero de cap√≠tulos
                    chapters = book.architecture.get('structure', {}).get('chapters', [])
                    chapter_count = len(chapters) if chapters else book.chapter_count or 10
                    
                    # Calcular palabras por cap√≠tulo promedio + 20%
                    words_per_chapter = int((estimated_words / chapter_count) * 1.2)
                    target_words = f"extenso y detallado (aproximadamente {words_per_chapter:,} palabras)"
                else:
                    target_words = "extenso y detallado"
            except Exception:
                # Si hay error en el c√°lculo, usar descripci√≥n gen√©rica
                target_words = "extenso y detallado"
        
        return f"""CAP√çTULO ACTUAL A REGENERAR:
{chapter_content}

FEEDBACK DEL USUARIO:
- Qu√© no le gusta: {feedback.get('whatDislike', '')}
- Qu√© quiere cambiar: {feedback.get('whatChange', '')}
- C√≥mo le gustar√≠a que quedara: {feedback.get('howWant', '')}

INSTRUCCIONES ESPEC√çFICAS DE REGENERACI√ìN:

**üéØ OBJETIVO PRINCIPAL:**
Regenera COMPLETAMENTE el cap√≠tulo considerando todo el feedback del usuario y aplicando las mejores pr√°cticas de escritura profesional.

**üìù FORMATO Y ESTRUCTURA REQUERIDOS:**
1. Mant√©n el t√≠tulo del cap√≠tulo (##) pero transforma completamente todo el contenido
2. Utiliza la estructura de formato Markdown profesional especificada en las instrucciones del sistema
3. Organiza el contenido en secciones l√≥gicas con encabezados H3 (###) y H4 (####) cuando sea necesario
4. Incluye listas, tablas, citas y elementos visuales en Markdown para mejorar la legibilidad
5. Aseg√∫rate de usar **texto en negrita** para conceptos clave y *cursiva* para √©nfasis

**üìä CONTENIDO Y EXTENSI√ìN:**
6. Haz el contenido mucho m√°s {target_words}
7. Desarrolla cada concepto con profundidad, incluyendo:
   - Explicaciones detalladas y claras
   - Ejemplos pr√°cticos y casos de estudio relevantes
   - An√©cdotas, datos, estad√≠sticas o contexto hist√≥rico cuando sea apropiado
   - M√∫ltiples perspectivas o enfoques del tema
8. Aseg√∫rate de que cada secci√≥n tenga suficiente contenido y desarrollo

**üé® CALIDAD Y TONO:**
9. Mant√©n un tono profesional pero accesible y atractivo para el lector
10. Crea transiciones suaves entre secciones para mantener el flujo narrativo
11. Termina el cap√≠tulo con una conclusi√≥n o s√≠ntesis que refuerce los puntos clave
12. Aseg√∫rate de que el resultado sea significativamente superior al contenido original

**‚úÖ RESULTADO ESPERADO:**
El cap√≠tulo regenerado debe ser un contenido completamente nuevo, mucho m√°s extenso, mejor organizado, y que responda espec√≠ficamente a todas las solicitudes del feedback del usuario.

üö® **OBLIGATORIEDAD CR√çTICA - TARGETING EN REGENERACI√ìN:**
- **PROMESA COMERCIAL**: Este cap√≠tulo regenerado forma parte de las p√°ginas prometidas al cliente
- **TARGET PALABRAS**: Generar aproximadamente {target_words} para cumplir expectativas
- **RESPONSABILIDAD**: Una regeneraci√≥n corta = Comprometer p√°ginas totales del libro
- **EXPANSI√ìN OBLIGATORIA**: Si el contenido natural no alcanza el target, expandir con valor
- **CALIDAD + CANTIDAD**: Mejorar seg√∫n feedback PERO mantener extensi√≥n adecuada
- **NO REDUCIR**: El feedback NO puede ser excusa para generar menos contenido

Regenera el cap√≠tulo ahora en formato Markdown siguiendo todas estas especificaciones:"""

    def _parse_markdown_architecture_elements(self, markdown_content: str, book_params: Dict[str, Any]) -> Dict[str, List[Dict[str, str]]]:
        """
        Parsea personajes y secciones especiales del contenido Markdown de regeneraci√≥n.
        Solo para backend - no afecta frontend existente.
        """
        import re
        
        characters = []
        special_sections = []
        
        # Parsear personajes - NUEVO FORMATO INLINE (prioridad)
        # Buscar patrones como: **Personaje principal**: *Ana Rodr√≠guez*, estudiante de intercambio
        inline_character_patterns = [
            r'\*\*Personaje principal\*\*:\s*\*([^*]+)\*,?\s*(.*?)(?=\n|$)',
            r'\*\*Personaje secundario\*\*:\s*\*([^*]+)\*,?\s*(.*?)(?=\n|$)', 
            r'\*\*Protagonista\*\*:\s*\*([^*]+)\*,?\s*(.*?)(?=\n|$)',
            r'\*\*Narrador\*\*:\s*\*([^*]+)\*,?\s*(.*?)(?=\n|$)'
        ]
        
        for pattern in inline_character_patterns:
            inline_matches = re.finditer(pattern, markdown_content, re.MULTILINE | re.IGNORECASE)
            for match in inline_matches:
                name = match.group(1).strip()
                description = match.group(2).strip()
                
                # Extraer rol del tipo de personaje del pattern
                role = "Personaje Principal"
                if "secundario" in pattern.lower():
                    role = "Personaje Secundario"
                elif "protagonista" in pattern.lower():
                    role = "Protagonista"
                elif "narrador" in pattern.lower():
                    role = "Narrador"
                
                if name and len(name) > 1:
                    characters.append({
                        "name": name,
                        "role": role,
                        "description": description or f"Personaje en {book_params.get('title', 'el libro')}"
                    })
        
        # Parsear personajes - FORMATO TRADICIONAL (para compatibilidad)
        # Solo si no encontramos personajes en formato inline
        if not characters:
            character_section_patterns = [
                r'### \*\*PERSONAJES RECURRENTES\*\*.*?\n(.*?)(?=\n### |\n## |\n# |$)',
                r'## \*\*üë• PERSONAJES GU√çA DEL LIBRO\*\*.*?\n(.*?)(?=\n## |\n# |$)',
                r'## üé≠ PERSONAJES.*?\n(.*?)(?=\n## |\n# |$)',
                r'## PERSONAJES.*?\n(.*?)(?=\n## |\n# |$)',
                r'# PERSONAJES.*?\n(.*?)(?=\n## |\n# |$)'
            ]
            
            for pattern in character_section_patterns:
                character_match = re.search(pattern, markdown_content, re.DOTALL | re.IGNORECASE)
                if character_match:
                    character_content = character_match.group(1)
                    
                    # Extraer personajes individuales (formato: ### **üéì Herr Professor Schmidt**)
                    character_blocks = re.findall(r'### \*\*(.+?)\*\*.*?\n(.*?)(?=\n### |\n## |\n# |$)', character_content, re.DOTALL)
                    
                    for char_name_line, char_details in character_blocks:
                        # Limpiar nombre (remover emojis y formateo)
                        name_match = re.search(r'(?:[üéìüíºüéíüåç]\s*)?(.+?)$', char_name_line.strip())
                        name = name_match.group(1).strip() if name_match else char_name_line.strip()
                        
                        # Extraer rol de la l√≠nea con *El Acad√©mico Tradicional*
                        role_match = re.search(r'>\s*\*([^*]+)\*', char_details)
                        role = role_match.group(1).strip() if role_match else "Personaje Principal"
                        
                        # Extraer descripci√≥n de las l√≠neas de rol o bullets
                        desc_lines = []
                        for line in char_details.split('\n'):
                            line = line.strip()
                            if line.startswith('- **Rol:**'):
                                bullet_match = re.search(r'- \*\*Rol:\*\*\s*(.*)', line)
                                if bullet_match:
                                    desc_lines.append(bullet_match.group(1))
                            elif line.startswith('- **Especialidad:**'):
                                bullet_match = re.search(r'- \*\*Especialidad:\*\*\s*(.*)', line)
                                if bullet_match:
                                    desc_lines.append(bullet_match.group(1))
                            elif line.startswith('- **Estilo:**'):
                                bullet_match = re.search(r'- \*\*Estilo:\*\*\s*(.*)', line)
                                if bullet_match:
                                    desc_lines.append(bullet_match.group(1))
                        
                        description = '. '.join(desc_lines) if desc_lines else f"Personaje gu√≠a especializado en {book_params.get('title', 'el libro')}"
                        
                        if name and len(name) > 1:  # Validar que tiene contenido v√°lido
                            characters.append({
                                "name": name,
                                "role": role,
                                "description": description
                            })
                    
                    break  # Solo procesar la primera secci√≥n de personajes encontrada
        
        # Parsear secciones especiales - NUEVO FORMATO BULLET POINTS (prioridad)
        # Buscar patrones como: - **Secciones especiales**: seguido de bullet points con emojis
        bullet_special_pattern = r'- \*\*Secciones especiales\*\*:?\s*\n((?:\s*- [üìùüí°üéØ‚ö°üîçüìö][^\n]*\n?)+)'
        bullet_match = re.search(bullet_special_pattern, markdown_content, re.MULTILINE | re.IGNORECASE)
        
        if bullet_match:
            bullet_content = bullet_match.group(1)
            # Extraer cada bullet point con emoji (con espacios opcionales al inicio)
            bullet_sections = re.findall(r'\s*- ([üìùüí°üéØ‚ö°üîçüìö])\s*\*\*([^*]+)\*\*:?\s*(.*?)(?=\n|$)', bullet_content, re.MULTILINE)
            
            for emoji, section_name, section_desc in bullet_sections:
                section_type = section_name.strip()
                description = section_desc.strip()
                
                # Valores por defecto basados en el emoji y tipo
                frequency = "Seg√∫n sea necesario"
                purpose = description or f"Elemento especial que mejora la experiencia de lectura en {book_params.get('title', 'el libro')}"
                
                # Ajustar frecuencia seg√∫n el tipo detectado
                if "ejercicio" in section_type.lower() or "pr√°ctica" in section_type.lower():
                    frequency = "2-3 por cap√≠tulo"
                elif "vocabulario" in section_type.lower() or "glosario" in section_type.lower():
                    frequency = "1 por cap√≠tulo"
                elif "consejo" in section_type.lower() or "tip" in section_type.lower():
                    frequency = "2-3 por cap√≠tulo"
                elif "cultural" in section_type.lower() or "contexto" in section_type.lower():
                    frequency = "1-2 por cap√≠tulo"
                
                if section_type and len(section_type) > 1:
                    special_sections.append({
                        "type": section_type,
                        "frequency": frequency,
                        "purpose": purpose
                    })
        
        # Parsear secciones especiales - FORMATO TRADICIONAL (para compatibilidad)
        # Solo si no encontramos secciones en formato bullet points
        if not special_sections:
            special_section_patterns = [
                r'## \*\*üîß SECCIONES ESPECIALES EXTRA√çBLES\*\*.*?\n(.*?)(?=\n## |\n# |$)',
                r'## üîß SECCIONES.*?\n(.*?)(?=\n## |\n# |$)',
                r'## SECCIONES ESPECIALES.*?\n(.*?)(?=\n## |\n# |$)',
                r'# SECCIONES ESPECIALES.*?\n(.*?)(?=\n## |\n# |$)'
            ]
            
            for pattern in special_section_patterns:
                section_match = re.search(pattern, markdown_content, re.DOTALL | re.IGNORECASE)
                if section_match:
                    section_content = section_match.group(1)
                    
                    # Extraer secciones individuales (formato: ### **üí° CONSEJO DEL EXPERTO**)
                    section_blocks = re.findall(r'### \*\*(.+?)\*\*.*?\n(.*?)(?=\n### |\n## |\n# |$)', section_content, re.DOTALL)
                    
                    for section_type_line, section_details in section_blocks:
                        # Limpiar tipo de secci√≥n (remover emojis)
                        type_match = re.search(r'(?:[üí°üéØüìù‚ö°üîçüìö]\s*)?(.+?)$', section_type_line.strip())
                        section_type = type_match.group(1).strip() if type_match else section_type_line.strip()
                        
                        # Valores por defecto basados en el tipo de secci√≥n
                        frequency = "Seg√∫n sea necesario"
                        purpose = f"Elemento especial que mejora la experiencia de lectura en {book_params.get('title', 'el libro')}"
                        
                        # Intentar extraer informaci√≥n espec√≠fica de los bloques de c√≥digo markdown
                        if "CONSEJO DEL EXPERTO" in section_type:
                            frequency = "2-3 por cap√≠tulo"
                            purpose = "Consejos pr√°cticos y profesionales de expertos para mejorar el dominio del alem√°n"
                        elif "ENFOQUE PR√ÅCTICO" in section_type:
                            frequency = "1 por cap√≠tulo"
                            purpose = "Aplicaciones pr√°cticas de las expresiones en situaciones reales espec√≠ficas"
                        elif "EJERCICIO R√ÅPIDO" in section_type:
                            frequency = "2-3 por cap√≠tulo"
                            purpose = "Actividades interactivas para practicar y consolidar las expresiones aprendidas"
                        elif "EXPRESI√ìN DEL D√çA" in section_type:
                            frequency = "1 por cap√≠tulo"
                            purpose = "Destacar una expresi√≥n especialmente √∫til con explicaci√≥n detallada y contexto cultural"
                        elif "AN√ÅLISIS CULTURAL" in section_type:
                            frequency = "1-2 por cap√≠tulo"
                            purpose = "Explicaciones del contexto cultural alem√°n para usar las expresiones apropiadamente"
                        elif "VOCABULARIO CLAVE" in section_type:
                            frequency = "1 por cap√≠tulo"
                            purpose = "Tablas organizadas con vocabulario esencial relacionado con las expresiones del cap√≠tulo"
                        
                        if section_type and len(section_type) > 1:  # Validar contenido v√°lido
                            special_sections.append({
                                "type": section_type,
                                "frequency": frequency,
                                "purpose": purpose
                            })
                    
                    break  # Solo procesar la primera secci√≥n especial encontrada
        
        return {
            "personajes": characters,
            "secciones_especiales": special_sections
        }

    def estimate_thinking_tokens(self, thinking_content) -> int:
        """
        Estima el n√∫mero de thinking tokens basado en el contenido de thinking.
        
        Como la API de Anthropic no siempre reporta thinking_tokens correctamente,
        calculamos una estimaci√≥n basada en el contenido capturado.
        
        Args:
            thinking_content: El texto del thinking content capturado (str) o lista de strings
            
        Returns:
            Estimaci√≥n de thinking tokens (int)
        """
        # Manejar tanto listas como cadenas para mayor robustez
        if isinstance(thinking_content, list):
            thinking_content = ''.join(thinking_content)
        elif not isinstance(thinking_content, str):
            thinking_content = str(thinking_content)
            
        if not thinking_content or len(thinking_content.strip()) == 0:
            return 0
        
        # Limpiar el contenido para conteo m√°s preciso
        cleaned_content = thinking_content.strip()
        
        # M√©todo 1: Estimaci√≥n por caracteres (1 token ‚âà 4 caracteres)
        char_based_tokens = len(cleaned_content) // 4
        
        # M√©todo 2: Estimaci√≥n por palabras (1 token ‚âà 0.75 palabras) 
        words = len(cleaned_content.split())
        word_based_tokens = int(words / 0.75)
        
        # M√©todo 3: Estimaci√≥n h√≠brida considerando espacios y puntuaci√≥n
        # Contar tokens m√°s precisamente considerando:
        # - Palabras regulares
        # - N√∫meros 
        # - Puntuaci√≥n
        # - Espacios y saltos de l√≠nea
        
        import re
        
        # Contar diferentes tipos de elementos
        word_tokens = len(re.findall(r'\b\w+\b', cleaned_content))  # Palabras
        number_tokens = len(re.findall(r'\b\d+\b', cleaned_content))  # N√∫meros
        punct_tokens = len(re.findall(r'[.!?;:,\-(){}[\]"]', cleaned_content))  # Puntuaci√≥n
        newline_tokens = cleaned_content.count('\n')  # Saltos de l√≠nea
        
        # Estimaci√≥n m√°s precisa
        estimated_tokens = word_tokens + (number_tokens * 0.8) + (punct_tokens * 0.3) + (newline_tokens * 0.1)
        
        # Usar promedio ponderado de los tres m√©todos
        # Dar m√°s peso al m√©todo h√≠brido que es m√°s preciso
        final_estimate = int(
            (char_based_tokens * 0.2) + 
            (word_based_tokens * 0.3) + 
            (estimated_tokens * 0.5)
        )
        
        # Aplicar l√≠mites razonables
        min_tokens = max(1, len(cleaned_content) // 6)  # M√≠nimo conservador
        max_tokens = len(cleaned_content) // 2  # M√°ximo conservador
        
        final_estimate = max(min_tokens, min(final_estimate, max_tokens))
        
        return final_estimate


# Singleton instance
_claude_service: Optional[ClaudeService] = None


def get_claude_service() -> ClaudeService:
    """Get or create Claude service instance."""
    global _claude_service
    if _claude_service is None:
        _claude_service = ClaudeService()
    return _claude_service